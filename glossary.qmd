# Key Concepts {-}

These are the key concepts from the *Primer*. You should apply them whenever you face a choice, and some data to help you make it. The world confronts us. Makes decisions we must.

**Quantity of Interest** is the number which you want to estimate. You will almost always calculate a posterior probability distribution for your Quantity of Interest since, in the real world, it is almost always impossible to determine your QoI precisely.

**Preceptor Table** is a table of data with rows and columns such that, if there is no missing data, it is easy to estimate the quantity of interest.

[**Potential Outcome**](https://www.econometrics-with-r.org/13-1-poceaie.html) is the outcome for an individual under a potential treatment.

**Causal Effect** is the difference between two potential outcomes.

[**Rubin Causal Model**](https://en.wikipedia.org/wiki/Rubin_causal_model) is an approach to the statistical analysis of cause and effect based on the framework of potential outcomes.

**Predictive Models and Causal Models** are different because predictive models have only one outcome column. Causal Models have more than one (potential) outcome columns because we need more than one potential outcome in order to estimate a *causal effect*.

**Units**, **outcomes** and **covariates** are important parts of every data science model. Causal, but not predictive, models also include **treatments**, which are just covariates which we can manipulate.

**Wisdom** is the first [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) in data science. Begin with the quantity of interest. Is that QoI a causal effect or simply a forecast? What Preceptor Table would allow you to calculate your QoI easily? Perform an exploratory data analysis (EDA) on the data you have. Is it *valid* to consider the data you have and the (theoretical) data from the Preceptor Table to have arisen out of the same population? If so, you may continue. If not, your attempt to estimate your QoI ends now.

**Validity** is the consistency, or lack there of, in the columns of our dataset and the corresponding columns in our Preceptor Table. In order to consider the two datasets to be drawn from the same population, the columns from one must be have a valid correspondence with the columns in the other. Validity, if true (or at least reasonable), allows us to construct the Population Table.

**Population Table** can be constructed if the validity assumption is (mostly) true. It includes all the rows and columns from the Preceptor Table. It also includes the rows and columns from the data set. It generally has other rows as well, rows which represent unit/time combinations from other components of the population.

**Justice** is the second [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) in data science. Justice starts with the Population Table – the data we want to have, the data which we actually have, and all the other data from that same population. Each row of the Population Table is defined by a unique Unit/Time combination. We explore three key issues about the Population Table. First, does the relationship among the variables demonstrate stability, meaning is the model stable across different time periods? Second, are the rows associated with the data representative of all the units which we might have had data for from that time period? Third, for causal models only, we consider unconfoundedness. Justice concludes by making an assumption about the data generating mechanism. Which general mathematical formula connects the outcome variable we are interested in with the other data that we have?

**Stability** means that the relationship between the columns in the Population Table is the same for three categories of rows: the data, the Preceptor Table, and the larger population from which both are drawn.

**Representativeness**, or the lack thereof, concerns two relationship, among the rows in the Population Table. The first is between the Preceptor Table and the other rows. The second is between our data and the other rows. Ideally, we would like both the Preceptor Table *and* our data to be random samples from the population. Sadly, this is almost never the case.

**Unconfoundedness** means that the treatment assignment is independent of the potential outcomes, when we condition on pre-treatment covariates. This assumption is only relevant for causal models. We write that a model is "confounded" if this is not true. The easiest way to ensure unconfoundedness is to randonly assign treatment.

**Courage** is the third [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) in data science. Justice gave us the data and the structure of the model. Courage allows us to explore different models. Even though Justice has provided the basic mathematical structure of the model, we still need to decide which variables to include and to estimate the values of unknown parameters. We avoid hypothesis tests. We check our models for consistency with the data we have. We select one model.

**Temperance** is the fourth [Cardinal Virtue](https://en.wikipedia.org/wiki/Cardinal_virtues) in data science. Courage gave us the fitted model. Temperance guides us in the use of the model we have created to answer the questions we began with. We create posteriors of the quantities of interest. We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.



