<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science</title>
<meta name="author" content="David Kane">
<meta name="generator" content="bookdown 0.26 with bs4_book()">
<meta property="og:title" content="Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science">
<meta property="og:type" content="book">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 5 Probability | Preceptor’s Primer for Bayesian Data Science">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script><script src="libs/plotly-binding-4.10.0/plotly.js"></script><script src="libs/typedarray-0.1/typedarray.min.js"></script><link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet">
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script><link href="libs/plotly-htmlwidgets-css-2.5.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="libs/plotly-main-2.5.1/plotly-latest.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="style.css">
<meta name="description" content="This chapter is a draft. There are errors. The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone...">
<meta property="og:description" content="This chapter is a draft. There are errors. The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone...">
<meta name="twitter:description" content="This chapter is a draft. There are errors. The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone...">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Preceptor’s Primer for Bayesian Data Science</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="preamble.html">Preamble</a></li>
<li><a class="" href="getting-started.html">Getting Started</a></li>
<li><a class="" href="visualization.html"><span class="header-section-number">1</span> Visualization</a></li>
<li><a class="" href="wrangling.html"><span class="header-section-number">2</span> Wrangling</a></li>
<li><a class="" href="data.html"><span class="header-section-number">3</span> Data</a></li>
<li><a class="" href="rubin-causal-model.html"><span class="header-section-number">4</span> Rubin Causal Model</a></li>
<li><a class="active" href="probability.html"><span class="header-section-number">5</span> Probability</a></li>
<li><a class="" href="one-parameter.html"><span class="header-section-number">6</span> One Parameter</a></li>
<li><a class="" href="two-parameters.html"><span class="header-section-number">7</span> Two Parameters</a></li>
<li><a class="" href="three-parameters.html"><span class="header-section-number">8</span> Three Parameters</a></li>
<li><a class="" href="four-parameters.html"><span class="header-section-number">9</span> Four Parameters</a></li>
<li><a class="" href="five-parameters.html"><span class="header-section-number">10</span> Five Parameters</a></li>
<li><a class="" href="n-parameters.html"><span class="header-section-number">11</span> N Parameters</a></li>
<li><a class="" href="tools.html">Tools</a></li>
<li><a class="" href="functions.html">Functions</a></li>
<li><a class="" href="maps.html">Maps</a></li>
<li><a class="" href="ipums.html">IPUMS</a></li>
<li><a class="" href="animation.html">Animation</a></li>
<li><a class="" href="set-up-for-working-on-the-primer.html">Set Up for Working on The Primer</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/PPBDS/primer">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="probability" class="section level1" number="5">
<h1>
<span class="header-section-number">5</span> Probability<a class="anchor" aria-label="anchor" href="#probability"><i class="fas fa-link"></i></a>
</h1>
<!-- Yuhan: Once I try to renv:restore terra package didn't seems to work. -->
<!-- Yuhan: In addition, when I try to download the package rgl it doesn't seems to work. Maybe this is the problem? -->
<!-- Yuhan: testing for git push. -->
<!-- For some reason, this now fails regularly with an error like "Error: C stack usage  8727068 is too close to the limit". Something has changed since June 2021. Highest priority is fixing this. Googling around it seems like others have seen this problem. Google also suggests that the cause is a recursive function call of some kind. For now, I have commented out the three or four places where plot_gg() is used. That has made the problem go away, but at the cost of losing our cool 3D plots. -->
<!-- Major change is that each example needs to have a simple question. Then it needs a DGM. Then we use the DGM to answer the question.  -->
<!-- Topics we don't currently address in the chapter but which we might add: population, Preceptor Table, Population Table. -->
<!-- How do we introduce the Question? We certainly need a question each time because, once we have the model, we have to show readers how to "work with" the distribution, and that requires a question to answer. Revisit this sentence: "All data science problems". -->
<!-- If A and B are independent, you can make a draw from the joint distribution of A and B --- p(A, B) --- by first taking a draw from A and combining it with a draw from B. Maybe this means discussing independence in the section of joint distributions? -->
<!-- The way that one does does so, is one draws 4,000 values from them, does some manipulation *row-by_row*, and then, hooray, you have you answer.  -->
<!-- You can consider these pdfs to be independent, so you can draw them independently and then --- this is the magic! --- you can treat a row as a draw from their joint distribution. -->
<!-- The joint distribution of a collection of random variables --- which we are working with by considering 4,000 draws from their pdfs --- is  . . . . the same as picking a random value from each member of the collection.  -->
<!-- There are two kinds of questions. The first asks for the value of a specific "real" number, like the height of the tallest person out of a 100. We answer this type of question with a posterior probability distribution. The second asks for the chances/likelihood/probability/odds of something --- like what are the chances that the tallest person will be above 200 cm. We answer this by first making a probability distribution and then calculating the appropriate area under the curve. -->
<!-- What would be a fun theme/gif/movie clip to start and end the chapter with, like we do in chapters 4 and 6? Something having to do with betting . . . Connected to Kant? -->
<!-- Add, after N models, a section on Infinite models, meaning a continuous parameter p. Note that we have a continuous distribution section now. Want to set the stage for Chapter 6, in which we are generating a posterior for p which we may think of as taking an infinite number of values. This is a key dimension on which chapter 5 and 6 need to connect. -->
<!-- Revisit these references and see if there is other stuff we should include. Rethinking marbles would make a nice tutorial. -->
<!-- Teaching Bayes' Rule: A Data-Oriented Approach by Jim Albert. -->
<!-- Rethinking Chapter 2. Garden of forking data is just excellent stuff. -->
<!-- Bayesian Workshop -->
<p><em>This chapter is a draft. There are errors.</em></p>
<blockquote>
<p>The usual touchstone of whether what someone asserts is mere persuasion or at least a subjective conviction, i.e., firm belief, is betting. Often someone pronounces his propositions with such confident and inflexible defiance that he seems to have entirely laid aside all concern for error. A bet disconcerts him. Sometimes he reveals that he is persuaded enough for one ducat but not for ten. For he would happily bet one, but at ten he suddenly becomes aware of what he had not previously noticed, namely that it is quite possible that he has erred. -— Immanuel Kant, <em>Critique of Pure Reason</em></p>
</blockquote>
<p>The central tension, and opportunity, in data science is the interplay between the <em>data</em> and the <em>science</em>, between our empirical observations and the models which we use to understand them. Probability is the language we use to explore that interplay; it connects models to data, and data to models.</p>
<p>What does it mean that Trump had a <em>30% chance</em> of winning election in the fall of 2016? That there is a <em>90% probability</em> of rain today? That the dice at the casino are <em>fair</em>?</p>
<p>Probability quantifies uncertainty. Think of <em>probability</em> as a proportion. The probability of an event occurring is a number from 0 to 1, where 0 means that the event is impossible and 1 means that the event is 100% certain.</p>
<p>Begin with the simplest events: coin flips and dice rolls. The set of all outcomes is the <em>sample space</em>. With fair coins and dice, we know that:</p>
<ul>
<li>The probability of rolling a 1 or a 2 is 2/6, or 1/3.</li>
<li>The probability of rolling a 1, 2, 3, 4, 5, or 6 is 1.<br>
</li>
<li>The probability of flipping a coin and getting tails is 1/2.</li>
</ul>
<p>If the probability of an outcome is unknown, we will often refer to it as an unknown <em>parameter</em>, something which we might use data to <em>estimate</em>. We usually use Greek letters to refer to parameters. Whenever we are talking about a specific probability (represented by a single value), we will use <span class="math inline">\(\rho\)</span> (the Greek letter “rho” but spoken aloud as “p” by us) with a <em>subscript</em> which specifies the exact outcome of which it is the probability. For instance, <span class="math inline">\(\rho_h = 0.5\)</span> denotes the probability of getting heads on a coin toss when the coin is fair. <span class="math inline">\(\rho_t\)</span> — spoken as “PT” or “P sub T” or “P tails” — denotes the probability of getting tails on a coin toss. This notation can become annoying if the outcome whose probability we seek is less concise. For example, we might write the probability of rolling a 1, 2 or 3 using a fair die as:</p>
<p><span class="math display">\[
\rho_{die\ roll\ is\ 1,\ 2\ or\ 3} = 0.5
\]</span></p>
<p>We will rarely write out the full definition of the event with the <span class="math inline">\(\rho\)</span> symbol. Instead, we will define an event “a” as when a rolled die equals 1, 2 or 3 and, then, write</p>
<p><span class="math display">\[\rho_a = 0.5\]</span></p>
<p>A <em>random variable</em> is a function which produces a value from a sample set. A random variable can be either discrete — where the sample set has a limited number of members, like H or T for the result of a coin flip, or 2, 3, …, 12 for the sum of two die — or continuous (any value within a range). Probability is a claim about the value of a random variable, i.e., that you have a 50% probability of getting a 1, 2 or 3 when you roll a fair die.</p>
<p>We usually use capital letters for random variables. So, <span class="math inline">\(C\)</span> might be our symbol for the random variable which is a coin toss and <span class="math inline">\(D\)</span> might be our symbol for the random variable which is the sum of two dice. When discussing random variables in general, or when we grow tired of coming up with new symbols, we will use <span class="math inline">\(Y\)</span>.</p>
<p>Small letters refer to a single outcome or result from a random variable. <span class="math inline">\(c\)</span> is the outcome from one coin toss. <span class="math inline">\(d\)</span> is the result from one throw of the dice. The value of the outcome must come from the sample space. So, <span class="math inline">\(c\)</span> can only take on two possible values: heads or tails. When discussing random variables in general, we use <span class="math inline">\(y\)</span> to refer to one outcome of the random variable <span class="math inline">\(Y\)</span>. If there are multiple outcomes — if we have, for example, flipped the coin multiple times — then we use subscripts to indicate the separate outcomes: <span class="math inline">\(y_1\)</span>, <span class="math inline">\(y_2\)</span>, and so on. The symbol for an arbitrary outcome is <span class="math inline">\(y_i\)</span>, where <span class="math inline">\(i\)</span> ranges from 1 through <span class="math inline">\(N\)</span>, the total number of events or experiments for which an outcome <span class="math inline">\(y\)</span> was produced.</p>
<p>The only package we need in this chapter is <strong>tidyverse</strong>.</p>
<div class="sourceCode" id="cb538"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://tidyverse.tidyverse.org">tidyverse</a></span><span class="op">)</span></code></pre></div>
<p>To understand probability more fully, we first need to understand distributions.</p>
<div id="distributions" class="section level2" number="5.1">
<h2>
<span class="header-section-number">5.1</span> Distributions<a class="anchor" aria-label="anchor" href="#distributions"><i class="fas fa-link"></i></a>
</h2>
<p>A variable in a tibble is a column, a vector of values. We sometimes refer to this vector as a “distribution.” This is somewhat sloppy in that a distribution can be many things, most commonly a mathematical formula. But, strictly speaking, a “frequency distribution” or an “empirical distribution” is a list of values, so this usage is not unreasonable.</p>
<div id="scaling-distributions" class="section level3" number="5.1.1">
<h3>
<span class="header-section-number">5.1.1</span> Scaling distributions<a class="anchor" aria-label="anchor" href="#scaling-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>Consider the vector which is the result of rolling one die 10 times.</p>
<div class="sourceCode" id="cb539"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">ten_rolls</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">5</span>, <span class="fl">5</span>, <span class="fl">1</span>, <span class="fl">5</span>, <span class="fl">4</span>, <span class="fl">2</span>, <span class="fl">6</span>, <span class="fl">2</span>, <span class="fl">1</span>, <span class="fl">5</span><span class="op">)</span></code></pre></div>
<p>There are other ways of storing the data in this vector. Instead of reporting every observation, we could record the number of times each value appears and the percentage of the total which this number accounts for.</p>
<div id="agtkogyswh" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#agtkogyswh .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#agtkogyswh .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#agtkogyswh .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#agtkogyswh .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#agtkogyswh .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#agtkogyswh .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#agtkogyswh .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#agtkogyswh .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#agtkogyswh .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#agtkogyswh .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#agtkogyswh .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#agtkogyswh .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#agtkogyswh .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#agtkogyswh .gt_from_md > :first-child {
  margin-top: 0;
}

#agtkogyswh .gt_from_md > :last-child {
  margin-bottom: 0;
}

#agtkogyswh .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#agtkogyswh .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#agtkogyswh .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#agtkogyswh .gt_row_group_first td {
  border-top-width: 2px;
}

#agtkogyswh .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#agtkogyswh .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#agtkogyswh .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#agtkogyswh .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#agtkogyswh .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#agtkogyswh .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#agtkogyswh .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#agtkogyswh .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#agtkogyswh .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#agtkogyswh .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#agtkogyswh .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#agtkogyswh .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#agtkogyswh .gt_left {
  text-align: left;
}

#agtkogyswh .gt_center {
  text-align: center;
}

#agtkogyswh .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#agtkogyswh .gt_font_normal {
  font-weight: normal;
}

#agtkogyswh .gt_font_bold {
  font-weight: bold;
}

#agtkogyswh .gt_font_italic {
  font-style: italic;
}

#agtkogyswh .gt_super {
  font-size: 65%;
}

#agtkogyswh .gt_two_val_uncert {
  display: inline-block;
  line-height: 1em;
  text-align: right;
  font-size: 60%;
  vertical-align: -0.25em;
  margin-left: 0.1em;
}

#agtkogyswh .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

#agtkogyswh .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#agtkogyswh .gt_slash_mark {
  font-size: 0.7em;
  line-height: 0.7em;
  vertical-align: 0.15em;
}

#agtkogyswh .gt_fraction_numerator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: 0.45em;
}

#agtkogyswh .gt_fraction_denominator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: -0.05em;
}
</style>
<div class="inline-table"><table class="gt_table">
<thead class="gt_header">
<tr>
<th colspan="3" class="gt_heading gt_title gt_font_normal" style>Distribution of Ten Rolls of a Fair Die</th>
    </tr>
<tr>
<th colspan="3" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style>Counts and percentages reflect the same information</th>
    </tr>
</thead>
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Outcome</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Count</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Percentage</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_right">2</td>
<td class="gt_row gt_right">0.2</td>
</tr>
<tr>
<td class="gt_row gt_right">2</td>
<td class="gt_row gt_right">2</td>
<td class="gt_row gt_right">0.2</td>
</tr>
<tr>
<td class="gt_row gt_right">4</td>
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_right">0.1</td>
</tr>
<tr>
<td class="gt_row gt_right">5</td>
<td class="gt_row gt_right">4</td>
<td class="gt_row gt_right">0.4</td>
</tr>
<tr>
<td class="gt_row gt_right">6</td>
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_right">0.1</td>
</tr>
</tbody>
</table></div>
</div>
<p>In this case, with only 10 values, it is actually less efficient to store the data like this. But what happens when we have 1,000 rolls?</p>
<div id="qvuxyhcywz" style="overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>html {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;
}

#qvuxyhcywz .gt_table {
  display: table;
  border-collapse: collapse;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#qvuxyhcywz .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qvuxyhcywz .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#qvuxyhcywz .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 0;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#qvuxyhcywz .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qvuxyhcywz .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#qvuxyhcywz .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#qvuxyhcywz .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#qvuxyhcywz .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#qvuxyhcywz .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#qvuxyhcywz .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#qvuxyhcywz .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
}

#qvuxyhcywz .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#qvuxyhcywz .gt_from_md > :first-child {
  margin-top: 0;
}

#qvuxyhcywz .gt_from_md > :last-child {
  margin-bottom: 0;
}

#qvuxyhcywz .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#qvuxyhcywz .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#qvuxyhcywz .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#qvuxyhcywz .gt_row_group_first td {
  border-top-width: 2px;
}

#qvuxyhcywz .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qvuxyhcywz .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#qvuxyhcywz .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#qvuxyhcywz .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qvuxyhcywz .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#qvuxyhcywz .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#qvuxyhcywz .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#qvuxyhcywz .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#qvuxyhcywz .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qvuxyhcywz .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-left: 4px;
  padding-right: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#qvuxyhcywz .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#qvuxyhcywz .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#qvuxyhcywz .gt_left {
  text-align: left;
}

#qvuxyhcywz .gt_center {
  text-align: center;
}

#qvuxyhcywz .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#qvuxyhcywz .gt_font_normal {
  font-weight: normal;
}

#qvuxyhcywz .gt_font_bold {
  font-weight: bold;
}

#qvuxyhcywz .gt_font_italic {
  font-style: italic;
}

#qvuxyhcywz .gt_super {
  font-size: 65%;
}

#qvuxyhcywz .gt_two_val_uncert {
  display: inline-block;
  line-height: 1em;
  text-align: right;
  font-size: 60%;
  vertical-align: -0.25em;
  margin-left: 0.1em;
}

#qvuxyhcywz .gt_footnote_marks {
  font-style: italic;
  font-weight: normal;
  font-size: 75%;
  vertical-align: 0.4em;
}

#qvuxyhcywz .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#qvuxyhcywz .gt_slash_mark {
  font-size: 0.7em;
  line-height: 0.7em;
  vertical-align: 0.15em;
}

#qvuxyhcywz .gt_fraction_numerator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: 0.45em;
}

#qvuxyhcywz .gt_fraction_denominator {
  font-size: 0.6em;
  line-height: 0.6em;
  vertical-align: -0.05em;
}
</style>
<div class="inline-table"><table class="gt_table">
<thead class="gt_header">
<tr>
<th colspan="3" class="gt_heading gt_title gt_font_normal" style>Distribution of One Thousand Rolls of a Fair Die</th>
    </tr>
<tr>
<th colspan="3" class="gt_heading gt_subtitle gt_font_normal gt_bottom_border" style>Counts and percentages reflect the same information</th>
    </tr>
</thead>
<thead class="gt_col_headings"><tr>
<th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Outcome</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Count</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_right" rowspan="1" colspan="1">Percentage</th>
    </tr></thead>
<tbody class="gt_table_body">
<tr>
<td class="gt_row gt_right">1</td>
<td class="gt_row gt_right">190</td>
<td class="gt_row gt_right">0.19</td>
</tr>
<tr>
<td class="gt_row gt_right">2</td>
<td class="gt_row gt_right">138</td>
<td class="gt_row gt_right">0.14</td>
</tr>
<tr>
<td class="gt_row gt_right">3</td>
<td class="gt_row gt_right">160</td>
<td class="gt_row gt_right">0.16</td>
</tr>
<tr>
<td class="gt_row gt_right">4</td>
<td class="gt_row gt_right">173</td>
<td class="gt_row gt_right">0.17</td>
</tr>
<tr>
<td class="gt_row gt_right">5</td>
<td class="gt_row gt_right">169</td>
<td class="gt_row gt_right">0.17</td>
</tr>
<tr>
<td class="gt_row gt_right">6</td>
<td class="gt_row gt_right">170</td>
<td class="gt_row gt_right">0.17</td>
</tr>
</tbody>
</table></div>
</div>
<p>Instead of keeping around a vector of length 1,000, we can just keep 12 values — the 6 possible outcomes and their frequency — without losing any information.</p>
<p>Two distributions can be identical even if they are of very different lengths. Let’s compare our original distribution of 10 rolls of the die with another distribution which just features 100 copies of those 10 rolls.</p>
<div class="sourceCode" id="cb540"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">more_rolls</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="va">ten_rolls</span>, <span class="fl">100</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-371-1.png" width="100%"></div>
<p>The two graphs have the exact same shape because, even though the vectors are of different lengths, the relative proportions of the outcomes are identical. In some sense, both vectors are from the same distribution. <em>Relative proportions, not the total counts, are what matter.</em></p>
</div>
<div id="normalizing-distributions" class="section level3" number="5.1.2">
<h3>
<span class="header-section-number">5.1.2</span> Normalizing distributions<a class="anchor" aria-label="anchor" href="#normalizing-distributions"><i class="fas fa-link"></i></a>
</h3>
<p>If two distributions have the same shape, then they only differ by the labels on the y-axis. There are various ways of “normalizing” distributions to make them all the same scale. The most common scale is one in which the area under the distribution adds to 1, e.g., 100%. For example, we can transform the plots above to look like:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-372-1.png" width="100%"></div>
<p>We sometimes refer to a distribution as “unnormalized” if the area under the curve does not add up to 1.</p>
</div>
<div id="simulating-distributions" class="section level3" number="5.1.3">
<h3>
<span class="header-section-number">5.1.3</span> Simulating distributions<a class="anchor" aria-label="anchor" href="#simulating-distributions"><i class="fas fa-link"></i></a>
</h3>
<p><em>There are two distinct concepts: a distribution and a set values drawn from that distribution.</em> But, in everyday use, we use “distribution” for both. When given a distribution (meaning a vector of numbers), we often use <code><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram()</a></code> or <code><a href="https://ggplot2.tidyverse.org/reference/geom_density.html">geom_density()</a></code> to graph it. But, sometimes, we don’t want to look at the whole thing. We just want some summary measures which report the key aspects of the distribution. The two most important attributes of a distribution are its <em>center</em> and its <em>variation</em> around that center.</p>
<p>We use <code><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize()</a></code> to calculate statistics for a variable, a column, a vector of values or a distribution. Note the language sloppiness. For the purposes of this book, “variable,” “column,” “vector,” and “distribution” all mean the same thing. Popular statistical functions include: <code><a href="https://rdrr.io/r/base/mean.html">mean()</a></code>, <code><a href="https://rdrr.io/r/stats/median.html">median()</a></code>, <code><a href="https://rdrr.io/r/base/Extremes.html">min()</a></code>, <code><a href="https://rdrr.io/r/base/Extremes.html">max()</a></code>, <code><a href="https://dplyr.tidyverse.org/reference/context.html">n()</a></code> and <code><a href="https://rdrr.io/r/base/sum.html">sum()</a></code>. Functions which may be new to you include three measures of the “spread” of a distribution: <code><a href="https://rdrr.io/r/stats/sd.html">sd()</a></code> (the standard deviation), <code><a href="https://rdrr.io/r/stats/mad.html">mad()</a></code> (the scaled median absolute deviation) and <code><a href="https://rdrr.io/r/stats/quantile.html">quantile()</a></code>, which is used to calculate an <em>interval</em> which includes a specified proportion of the values.</p>
<!-- *A distribution is a function that shows the possible values of a variable and how often they occur.* DK: I like this! But where to include it? -->
<p>Think of the distribution of a variable as an urn from which we can pull out, at random, values for that variable. Drawing a thousand or so values from that urn, and then looking at a histogram, can show where the values are centered and how they vary. Because people are sloppy, they will use the word distribution to refer to at least three related entities:</p>
<ol style="list-style-type: decimal">
<li>the (imaginary!) urn from which we are drawing values.</li>
<li>all the values in the urn</li>
<li>all the values which we have drawn from the urn, whether that be 10 or 1,000</li>
</ol>
<p>Sloppiness in the usage of the word distribution is universal. However, keep three distinct ideas separate:</p>
<ul>
<li><p>The <em>unknown true distribution</em> which, in reality, generates the data which we see. Outside of stylized examples in which we <em>assume</em> that a distribution follows a simple mathematical formula, we will never have access to the unknown true distribution. We can only estimate it. This unknown true distribution is often referred to as the <em>data generating mechanism</em>, or DGM. It is a function or black box or urn which produces data. We can see the data. We can’t see the urn.</p></li>
<li><p>The <em>estimated distribution</em> which, we think, generates the data which we see. Again, we can never know the unknown true distribution. But, by making some assumptions and using the data we have, we can <em>estimate</em> a distribution. Our estimate may be very close to the true distribution. Or it may be far away. The main task of data science to to create and use these estimated distributions. Almost always, these distributions are instantiated in computer code. Just as there is a <em>true</em> data generating mechanism associated with the (unknown) <em>true</em> distribution, there is an <em>estimated</em> data generating mechanism associated with the <em>estimated</em> ditribution.</p></li>
<li><p>A <em>vector of numbers drawn</em> from the estimated distribution. Both true and estimated distributions can be complex animals, difficult to describe accurately and in detail. But a vector of numbers drawn from a distribution is easy to understand and use. So, in general, we work with vectors of numbers. When someone — either a colleague or a piece of R code — creates a distribution which we want to use to answer a question, we don’t really want the distribution itself. Rather, we want a vectors of “draws” from that distribution. Vectors are easy to work with! Complex computer code is not.</p></li>
</ul>
<p>Again, people (including us!) will often be sloppy and use the same word, “distribution,” without making it clear whether they are talking about the <em>true distribution</em>, the <em>estimated distribution</em>, or a vector of <em>draws</em> from the estimated distribution. The same sloppiness applies to the use of the term <em>data generating mechanism</em>. Try not to be sloppy.</p>
<p>Much of the rest of the <em>Primer</em> involves learning how to work with distributions, which generally means working with the draws from those distributions. Fortunately, the usual rules of arithmetic apply. You can add/subtract/multiply/divide distributions by working with draws from those distributions, just as you can add/subtract/multiply/divide regular numbers.</p>
<!-- Also need to talk more about working with distributions, especially calculating areas under the curve. Maybe do this under each example below. -->
</div>
</div>
<div id="probability-distributions" class="section level2" number="5.2">
<h2>
<span class="header-section-number">5.2</span> Probability distributions<a class="anchor" aria-label="anchor" href="#probability-distributions"><i class="fas fa-link"></i></a>
</h2>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:unnamed-chunk-373"></span>
<img src="05-probability/images/de_finetti.jpg" alt='Bruno de Finetti, an Italian statistician who wrote a famous treatise on the theory of probability that began with the statement "PROBABILITY DOES NOT EXIST."' width="60%"><p class="caption">
FIGURE 5.1: Bruno de Finetti, an Italian statistician who wrote a famous treatise on the theory of probability that began with the statement “PROBABILITY DOES NOT EXIST.”
</p>
</div>
<p>For the purposes of this <em>Primer</em>, a <em>probability distribution</em> is a mathematical object which maps a set of outcomes to probabilities, where each distinct outcome has a chance of occurring between 0 and 1 inclusive. The probabilities must sum to 1. The set of possible outcomes, i.e., the sample space — heads or tails for the coin, 1 through 6 for a single die, 2 through 12 for the sum of a pair of dice — can be either discrete or continuous. Remember, discrete data can only take on certain values. Continuous data, like height and weight, can take any value within a range. The set of outcomes is the <em>domain</em> of the probability distribution. The <em>range</em> is the associated probabilities.</p>
<!-- DK: Make this connection clearer with a graphic or a table? Might not be worth the trouble since we don't use the terms domain and range again. -->
<p>Assume that a probability distribution is created by a <em>probability function</em>, a set function which maps outcomes to probabilities. The concept of a “probability function” is often split into two categories: probability <em>mass</em> functions (for discrete random variables) and probability <em>density</em> functions (for continuous random variables). As usual, we will be a bit sloppy, using the term probability distribution for both the mapping itself and for the function which creates the mapping.</p>
<p>We discuss three types of probability distributions: <em>empirical</em>, <em>mathematical</em>, and <em>posterior</em>.</p>
<p>The key difference between a <em>distribution</em>, as we have explored them in Section <a href="probability.html#distributions">5.1</a>, and a <em>probability</em> distribution is the requirement that the sum of the probabilities of the individual outcomes must be exactly 1. There is no such requirement for a distribution in general. But any distribution can be turned into a probability distribution by “normalizing” it. In this context, we will often refer to a distribution which is not (yet) a probability distribution as an “unnormalized” distribution.</p>
<p>Pay attention to notation. Recall that when we are talking about a specific probability (represented by a single value), we will use <span class="math inline">\(\rho\)</span> (the Greek letter “rho”) with a <em>subscript</em> which specifies the exact outcome of which it is the probability. For instance, <span class="math inline">\(\rho_h = 0.5\)</span> denotes the probability of getting heads on a coin toss when the coin is fair. <span class="math inline">\(\rho_t\)</span> — spoken as “PT” or “P sub T” or “P tails” — denotes the probability of getting tails on a coin toss. However, when we are referring to the entire probability distribution over a set of outcomes, we will use <span class="math inline">\(P()\)</span>. For example, the probability distribution of a coin toss is <span class="math inline">\(P(\text{coin})\)</span>. That is, <span class="math inline">\(P(\text{coin})\)</span> is composed of the two specific probabilities (50% and 50%) mapped from the two values in the domain (Heads and Tails). Similarly, <span class="math inline">\(P(\text{sum of two dice})\)</span> is the probability distribution over the set of 11 outcomes (2 through 12) which are possible when you take the sum of two dice. <span class="math inline">\(P(\text{sum of two dice})\)</span> is made up of 11 numbers — <span class="math inline">\(\rho_2\)</span>, <span class="math inline">\(\rho_3\)</span>, …, <span class="math inline">\(\rho_{12}\)</span> — each representing the unknown probability that the sum will equal their value. That is, <span class="math inline">\(\rho_2\)</span> is the probability of rolling a 2.</p>
<div id="flipping-a-coin" class="section level3" number="5.2.1">
<h3>
<span class="header-section-number">5.2.1</span> Flipping a coin<a class="anchor" aria-label="anchor" href="#flipping-a-coin"><i class="fas fa-link"></i></a>
</h3>
<p>All data science problems start with a question. Example: <em>What are the chances of getting three heads in a row when flipping a fair coin?</em> All questions are answered with the help of probability distributions.</p>
<p>An <em>empirical distribution</em> is based on data. You can think of this as the probability distribution created by running a simulation. In theory, if we increase the number of coins we flip in our simulation, the empirical distribution will look more and more similar to the mathematical distribution. The mathematical distribution is the Platonic form. The empirical distribution will often look like the mathematical probability distribution, but it will rarely be exactly the same.</p>
<p>In this simulation, there are 56 heads and 44 tails. The outcome will vary every time we run the simulation, but the proportion of heads to tails should not be too different if this coin is fair.</p>
<div class="sourceCode" id="cb541"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># We are flipping one fair coin a hundreds times. We need to get the same result</span>
<span class="co"># each time we create this graphic because we want the results to match the</span>
<span class="co"># description in the text. Using set.seed() guarantees that the random results</span>
<span class="co"># are the same each time. We define 0 as tails and 1 as heads.</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span>

<span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>results <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, <span class="fl">100</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">results</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes_eval.html">after_stat</a></span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, 
                   binwidth <span class="op">=</span> <span class="fl">0.5</span>, 
                   color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Empirical Probability Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Flipping one coin a hundred times"</span>,
         x <span class="op">=</span> <span class="st">"Outcome\nResult of Coin Flip"</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span><span class="op">)</span>, 
                       labels <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"Heads"</span>, <span class="st">"Tails"</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> 
                         <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/percent_format.html">percent_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-374-1.png" width="100%"></div>
<p>A <em>mathematical distribution</em> is based on a mathematical formula. Assuming that the coin is perfectly fair, we should, on average, get heads as often as we get tails.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-375-1.png" width="100%"></div>
<p>The distribution of a single observation is described by this formula.</p>
<p><span class="math display">\[ P(Y = y) = \begin{cases} 1/2 &amp;\text{for }y= \text{Heads}\\ 1/2 &amp;\text{for }y= \text{Tails} \end{cases}\]</span>
We sometimes do not know that the probability of heads and the probability of tails both equal 50%. In that case, we might write:</p>
<p><span class="math display">\[ P(Y = y) = \begin{cases} \rho_H &amp;\text{for }y= \text{Heads}\\ \rho_T &amp;\text{for }y= \text{Tails} \end{cases}\]</span></p>
<p>Yet, we know that, by definition, <span class="math inline">\(\rho_H + \rho_T = 1\)</span>, so we can rewrite the above asL</p>
<p><span class="math display">\[ P(Y = y) = \begin{cases} \rho_H &amp;\text{for }y= \text{Heads}\\ 1- \rho_H &amp;\text{for }y= \text{Tails} \end{cases}\]</span></p>
<p>Coin flipping (and related scenarios with only two possible outcomes) are such common problems, that the notation is often simplified further, with <span class="math inline">\(\rho\)</span> understood, by convention, to be the probability of heads. In that case, we can write the mathematical distribution is two canonical forms:</p>
<p><span class="math display">\[P(Y) = Bernoulli(\rho)\]</span>
and</p>
<p><span class="math display">\[y_i \sim Bernoulli(\rho)\]</span>
All five of these versions mean the same thing! The first four describe the mathematical probability distribution for a fair coin. The capital <span class="math inline">\(Y\)</span> within the <span class="math inline">\(P()\)</span> indicates a random variable. The fifth highlights one “draw” from that random variable, hence the lower case <span class="math inline">\(y\)</span> and the subscript <span class="math inline">\(i\)</span>.</p>
<p>Most probability distributions do not have special names, which is why we will use the generic symbol <span class="math inline">\(P\)</span> to define them. But some common probability distributions do have names, like “Bernoulli” in this case.</p>
<p>If the mathematical assumptions are correct, then as your sample size increases, the empirical probability distribution will look more and more like the mathematical distribution.</p>
<p>A <em>posterior distribution</em> is based on beliefs and expectations. It displays your belief about things you can’t see right now. You may have posterior distributions for outcomes in the past, present, or future.</p>
<p>In the case of the coin toss, the posterior distribution changes depending on your beliefs. For instance, let’s say your friend brought a coin to school and asked to bet you. If the result is heads, you have to pay them $5. In that case, your posterior probability distribution might look like this:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-376-1.png" width="100%"></div>
<p>The full terminology is mathematical (or empirical or posterior) <em>probability</em> distribution. But we will often shorten this to just mathematical (or empirical or posterior) distribution. The word “probability” is understood, even if it is not present.</p>
<!-- DK: Not sure I like this. Maybe use `rbinom(n = 10, size = 13, prob = 0.5)` instead? Maybe show both? -->
<p>Recall the question with which we started this section: <em>What are the chances of getting three heads in a row when flipping a fair coin?</em> To answer this question, we need to use a probability distribution as our <em>data generating mechanism</em>. Fortunately, the <code><a href="https://rdrr.io/r/stats/Binomial.html">rbinom()</a></code> function allows us to generate the results for coin flips. For example:</p>
<div class="sourceCode" id="cb542"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">10</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span></code></pre></div>
<pre><code>##  [1] 1 1 0 1 1 0 0 0 0 0</code></pre>
<p>generates the results of 10 coin flips, where a result of heads is presented as <code>1</code> and tails as <code>0</code>. With this tool, we can generate 1,000 draws from our experiment:</p>
<div class="sourceCode" id="cb544"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>toss_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>,
       toss_2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>,
       toss_3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1,000 × 3
##    toss_1 toss_2 toss_3
##     &lt;int&gt;  &lt;int&gt;  &lt;int&gt;
##  1      0      1      1
##  2      0      1      1
##  3      0      1      0
##  4      0      0      1
##  5      1      1      0
##  6      1      0      1
##  7      1      0      0
##  8      1      0      1
##  9      0      0      1
## 10      0      1      1
## # … with 990 more rows</code></pre>
<p>Because the flips are independent, we can consider each row to be a draw from the experiment. Then, we simply count up the proportion of experiments in which resulted in three heads.</p>
<div class="sourceCode" id="cb546"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>toss_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>,
       toss_2 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span>,
       toss_3 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1000</span>, size <span class="op">=</span> <span class="fl">1</span>, prob <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>three_heads <span class="op">=</span> <span class="va">toss_1</span> <span class="op">+</span> <span class="va">toss_2</span> <span class="op">+</span> <span class="va">toss_3</span> <span class="op">==</span> <span class="fl">3</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>chance <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">three_heads</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##   chance
##    &lt;dbl&gt;
## 1  0.104</code></pre>
<p>This is close enough to the correct answer of <span class="math inline">\(1/8\)</span>th. If we increase the sample size, we will get closer to the truth.</p>
<p>This is our first example of using a data generating mechanism — meaning <code><a href="https://rdrr.io/r/stats/Binomial.html">rbinom()</a></code> — to answer a question. We will see many more in the chapters to come.</p>
</div>
<div id="rolling-two-dice" class="section level3" number="5.2.2">
<h3>
<span class="header-section-number">5.2.2</span> Rolling two dice<a class="anchor" aria-label="anchor" href="#rolling-two-dice"><i class="fas fa-link"></i></a>
</h3>
<p>We get an <em>empirical distribution</em> by rolling two dice a hundred times, either by hand or with a computer simulation. The result is not identical to the mathematical distribution because of the inherent randomness of the real world and/or of simulation.</p>
<div class="sourceCode" id="cb548"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># In the coin example, we create the vector ahead of time, and then assigned</span>
<span class="co"># that vector to a tibble. There was nothing wrong with that approach. And we</span>
<span class="co"># could do the same thing here. But the use of map_* functions is more powerful,</span>
<span class="co"># although it requires creating the 100 rows of the tibble at the start and then</span>
<span class="co"># doing things "row-by_row."</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">1</span><span class="op">)</span>

<span class="va">emp_dist_dice</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>die_1 <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op">(</span><span class="va">ID</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>die_2 <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op">(</span><span class="va">ID</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">6</span><span class="op">)</span>, size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>sum <span class="op">=</span> <span class="va">die_1</span> <span class="op">+</span> <span class="va">die_2</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">sum</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes_eval.html">after_stat</a></span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, 
                   binwidth <span class="op">=</span> <span class="fl">1</span>, 
                   color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Empirical Probability Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Sum from rolling two dice, replicated one hundred times"</span>,
         x <span class="op">=</span> <span class="st">"Outcome\nSum of Two Die"</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">2</span>, <span class="fl">12</span>, <span class="fl">1</span><span class="op">)</span>, labels <span class="op">=</span> <span class="fl">2</span><span class="op">:</span><span class="fl">12</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> 
                         <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/percent_format.html">percent_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span>

<span class="va">emp_dist_dice</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-380-1.png" width="100%"></div>
<p>We might consider labeling the y-axis in plots of empirical distributions as “Proportion” rather than “Probability” since it is an actual proportion, calculated from real (or simulated) data. We will keep it as “Probability” since we want to emphasize the parallels between mathematical, empirical and posterior probability distributions.</p>
<p>Our <em>mathematical distribution</em> tells us that, with a fair dice, the probability of getting 1, 2, 3, 4, 5, and 6 are equal: there is a 1/6 chance of each. When we roll two dice at the same time and sum the numbers, the values closest to the middle are more common than values at the edge because there are more combinations of numbers that add up to the middle values.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-381-1.png" width="100%"></div>
<p><span class="math display">\[ P(Y = y) = \begin{cases} \dfrac{y-1}{36} &amp;\text{for }y=1,2,3,4,5,6 \\ \dfrac{13-y}{36} &amp;\text{for }y=7,8,9,10,11,12 \\ 0 &amp;\text{otherwise} \end{cases} \]</span></p>
<p>The <em>posterior distribution</em> for rolling two dice a hundred times depends on your beliefs. If you take the dice from your Monopoly set, you have reason to believe that the assumptions underlying the mathematical distribution are true. However, if you walk into a crooked casino and a host asks you to play craps, you might be suspicious, just as in the “flipping a coin example” the word “suspicious” means you no longer trust the “population” where the mathematical and empircal distribution drawn their data from. For example, in craps, a come-out roll of 7 and 11 is a “natural,” resulting in a win for the “shooter” and a loss for the casino. You might expect those numbers to occur less often than they would with fair dice. Meanwhile, a come-out roll of 2, 3 or 12 is a loss for the shooter. You might also expect values like 2, 3 and 12 to occur more frequently. Your posterior distribution might look like this:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-382-1.png" width="100%"></div>
<p>Someone less suspicious of the casino would have a posterior distribution which looks more like the mathematical distribution.</p>
</div>
<div id="presidential-elections" class="section level3" number="5.2.3">
<h3>
<span class="header-section-number">5.2.3</span> Presidential elections<a class="anchor" aria-label="anchor" href="#presidential-elections"><i class="fas fa-link"></i></a>
</h3>
<p>Now let’s say we are building probability distributions for political events, like a presidential election. We want to know the probability that Democratic candidate wins X electoral votes, where X comes from the range of possible outcomes: 0 to 538. (The total number of electoral votes in US elections since 1964 is 538.)</p>
<p>The <em>empirical distribution</em> in this case could involve looking into past elections in the United States and counting the number of electoral votes that the Democrats won in each. For the empirical distribution, we create a tibble with electoral vote results from past elections. Looking at elections since 1964, we can observe that the number of electoral votes that the Democrats received in each one is different. Given that we only have 15 entries, it is difficult to draw conclusions or make predictions based off of this empirical distribution.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-383-1.png" width="100%"></div>
<p>We can build a <em>mathematical distribution</em> for X which assumes that the chances of the Democratic candidate winning any given state’s electoral votes is 0.5 and the results from each state are independent.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-384-1.png" width="100%"></div>
<p>If our assumptions about this mathematical distribution are correct (they are not), then as the sample size increase, the empirical distribution should look more and more similar to the our mathematical distribution.</p>
<p>However, the data from past elections is more than enough to demonstrate that the assumptions of the mathematical probability distribution above do not work for electoral votes. The model assumes that the Democrats have a 50% chance of receiving each of the 538 votes. Just looking at the mathematical probability distribution, we can observe that receiving 13 or 17 or 486 votes out of 538 would be extreme and almost impossible if the mathematical model were accurate. However, our empirical distribution shows that such extreme outcomes are quite common. Presidential elections have resulted in much bigger victories or defeats than this distribution seems to allow for.</p>
<p>The <em>posterior distribution</em> of electoral votes is a popular topic, and an area of strong disagreement, among data scientists. Consider this posterior from <em>FiveThirtyEight</em>.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-385-1.png" width="100%"></div>
<p>Here is a posterior from the FiveThirtyEight website from August 13, 2020. This was created using the same data as the above distribution, but simply displayed differently. For each electoral result, the height of the bar represents the probability that a given event will occur. However, there are no lablels y-axis telling us what the specific probability of each outcome is. And that is OK! The specific values are not that useful. If we removed the labels on our y-axes, would it matter?</p>
<div class="inline-figure"><img src="05-probability/images/fivethirtyeight.png" width="100%"></div>
<p>Here is the posterior from <em>The Economist</em>, also from August 13, 2020. This looks confusing at first because they chose to merge the axes for Republican and Democratic electoral votes. We can tell that <em>The Economist</em> was less optimistic, relative to <em>FiveThirtyEight</em>, about Trump’s chances in the election.</p>
<div class="inline-figure"><img src="05-probability/images/economist_aug13.png" width="100%"></div>
<p>These two models, built by smart people using similar data sources, have reached fairly different conclusions. Data science is difficult! There is not one “right” answer. Real life is not a problem set.</p>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-388"></span>
<img src="05-probability/images/538_versus_Economist.png" alt="Watch the makers of these two models throw shade at each other on Twitter! Eliot Morris is one of the primary authors of the Economist model. Nate Silver is in charge of 538. They don't seem to be too impressed with each other's work! More smack talk [here](https://statmodeling.stat.columbia.edu/2020/08/31/more-on-that-fivethirtyeight-prediction-that-biden-might-only-get-42-of-the-vote-in-florida/) and [here](https://statmodeling.stat.columbia.edu/2020/08/31/problem-of-the-between-state-correlations-in-the-fivethirtyeight-election-forecast/)." width="100%"><p class="caption">
FIGURE 5.2: Watch the makers of these two models throw shade at each other on Twitter! Eliot Morris is one of the primary authors of the Economist model. Nate Silver is in charge of 538. They don’t seem to be too impressed with each other’s work! More smack talk <a href="https://statmodeling.stat.columbia.edu/2020/08/31/more-on-that-fivethirtyeight-prediction-that-biden-might-only-get-42-of-the-vote-in-florida/">here</a> and <a href="https://statmodeling.stat.columbia.edu/2020/08/31/problem-of-the-between-state-correlations-in-the-fivethirtyeight-election-forecast/">here</a>.
</p>
</div>
<p>There are many political science questions you could explore with posterior distributions. They can relate to the past, present, or future.</p>
<ul>
<li>Past: How many electoral votes would Hilary Clinton have won if she had picked a different VP?</li>
<li>Present: What are the total campaign donations from Harvard faculty?</li>
<li>Future: How many electoral votes will the Democratic candidate for president win in 2024?</li>
</ul>
</div>
<div id="height" class="section level3" number="5.2.4">
<h3>
<span class="header-section-number">5.2.4</span> Height<a class="anchor" aria-label="anchor" href="#height"><i class="fas fa-link"></i></a>
</h3>
<p>Question: <em>What is the height of the next adult male we will meet?</em></p>
<p>The three examples above are all <em>discrete</em> probability distributions, meaning that the outcome variable can only take on a limited set of values. A coin flip has two outcomes. The sum of a pair of dice has 11 outcomes. The total electoral votes for the Democratic candidate has 539 possible outcomes. In the limit, we can also create <em>continuous</em> probability distributions which have an <em>infinite</em> number of possible outcomes. For example, the average height for an American male could be any real number between 0 inches and 100 inches. (Of course, an average value anywhere near 0 or 100 is absurd. The point is that the average could be 68.564, 68.5643, 68.56432 68.564327, or any real number.)</p>
<p>All the characteristics for discrete probability distributions which we reviewed above apply just as much to continuous probability distributions. For example, we can create mathematical, empirical and posterior probability distributions for continuous outcomes just as we did for discrete outcomes.</p>
<p>The <em>empirical distribution</em> involves using data from the National Health and Nutrition Examination Survey (NHANES). What we are doing here is instead making an model by ourself using some mathematical formula, we use the actual data, we can get the data from either simulated by our own like in the “flipping a coin” and “Rolling two dice” scenario, or we used the data from someone else, like the presidential election and this scenario.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-389-1.png" width="100%"></div>
<p><em>Mathematical distribution</em> is complete based on mathematical formula and assumptions like in the Flipping a coin session we assume that the coin is an perfectly fair coin where where the probability landing on heads or tails is equal. In this case, we assume that the average hight of men is 175 cm, as well as the standard deviation for height is around 9 cm. When we have these two values, the average which we also called the mean, and standard deviation (sd), we can create an normal distribution using the <code><a href="https://rdrr.io/r/stats/Normal.html">rnorm()</a></code> function. And an normal distribution is an good approximation and generalization for height in our scenario.</p>
<p>Mathematical Distribution:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-390-1.png" width="100%"></div>
<p>Again, the Normal distribution which is an probability distribution that is symmetric about the mean is described by this formula.</p>
<p><span class="math display">\[y_i \sim N(\mu, \sigma^2)\]</span>.</p>
<p>Each value <span class="math inline">\(y_i\)</span> is drawn from a normal distribution with parameters <span class="math inline">\(\mu\)</span> for the mean and <span class="math inline">\(\sigma\)</span> for the standard deviation. If the mathematical assumptions are correct in this case the two parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, then as our sample size increases, the empirical probability distribution will look more and more like the mathematical distribution.</p>
<p>The <em>posterior distribution</em> for heights depends on the context. Are we considering all the adult men in America? In that case, our posterior would probably look a lot like the empirical distribution using NHANES data. If we are being asked about the distribution of heights among players in the NBA, then our posterior might look like:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-391-1.png" width="100%"></div>
<p>Comments:</p>
<ul>
<li><p><em>Continuous variables are a myth.</em> Nothing that can be represented on a computer is <a href="https://cs.stackexchange.com/questions/71648/why-is-data-in-computer-science-considered-to-be-discrete">truly continuous</a>. Even something which appears continuous, like height, actually can only take on a (very large) set of discrete variables.</p></li>
<li><p>The math of continuous probability distributions can be tricky. Read <a href="https://drive.google.com/file/d/1VmkAAGOYCTORq1wxSQqy255qLJjTNvBI/view">a book</a> on mathematical probability for all the messy details. Little of that matters in applied work.</p></li>
<li><p>The most important difference is that, with discrete distributions, it makes sense to estimate the probability of a specific outcome. What is the probability of rolling a 9? With continuous distributions, this makes no sense because there are an infinite number of possible outcomes. <em>With continuous variables, we only estimate intervals.</em></p></li>
</ul>
<!-- DK: This is important. Give an example. Answer the question. --><p>Don’t worry about the distinctions between discrete and continuous outcomes, or between the discrete and continuous probability distributions which we will use to summarize our beliefs about those outcomes. The basic intuition is the same in both cases.</p>
</div>
<div id="joint-distributions" class="section level3" number="5.2.5">
<h3>
<span class="header-section-number">5.2.5</span> Joint distributions<a class="anchor" aria-label="anchor" href="#joint-distributions"><i class="fas fa-link"></i></a>
</h3>
<!-- DK: Should be p(A). Discuss p(A, B). Find a better example.  -->
<p>Recall that <span class="math inline">\(P(\text{coin})\)</span> is the probability distribution for the result of a coin toss. It includes two parts, the probability of heads (<span class="math inline">\(\rho_h\)</span>) and the probability of tails (<span class="math inline">\(\rho_t\)</span>). This is a <em>univariate</em> distribution because there is only one outcome, which can be heads or tails. If there is more than one outcome, then we have a <em>joint</em> distribution.</p>
<!-- DK: Use of "outcome" is sloppy. Does a single die roll have one outcome or 6? -->
<p>Joint distributions are also mathematical objects that cover a set of outcomes, where each distinct outcome has a chance of occurring between 0 and 1 and the sum of all chances must equal 1. The key to a joint distribution is it measures the chance that both events A and B will occur. The notation is <span class="math inline">\(P(A, B)\)</span>.</p>
<p>Let’s say that you are rolling two six-sided dice simultaneously. Die 1 is weighted so that there is a 50% chance of rolling a 6 and a 10% chance of each of the other values. Die 2 is weighted so there is a 50% chance of rolling a 5 and a 10% chance of rolling each of the other values. Let’s roll both dice 1,000 times. In previous examples involving two dice, we cared about the sum of results and not the outcomes of the first versus the second die of each simulation. With a joint distributions, the order matters; so instead of 11 possible outcomes on the x-axis of our distribution plot (ranging from 2 to 12), we have 36. Furthermore, a 2D probability distribution is not sufficient to represent all of the variables involved, so the joint distribution for this example is displayed using a 3D plot.</p>
</div>
<div id="conditional-distrubutions" class="section level3" number="5.2.6">
<h3>
<span class="header-section-number">5.2.6</span> Conditional distrubutions<a class="anchor" aria-label="anchor" href="#conditional-distrubutions"><i class="fas fa-link"></i></a>
</h3>
<p>Imagine that 60% of people in a community have a disease. A doctor develops a test to determine if a random person has the disease. However, this test isn’t 100% accurate. There is an 80% probability of correctly returning positive <strong>if the person has the disease</strong> and 90% probability of correctly returning negative <strong>if the person does not have the disease</strong>.</p>
<p>The probability of a random person having the disease is 0.6. Since each person either has the disease or doesn’t (those are the only two possibilities), the probability that a person does not have the disease is <span class="math inline">\(1 - 0.6 = 0.4\)</span>.</p>
<div class="inline-figure"><img src="05-probability/images/tree-2.png" width="100%"></div>
<ul>
<li><p><em>If</em> the random person has the disease, then we go up the top branch. The probability of an infected person testing positive is 0.8 because the test is 80% sure of correctly returning positive when the person has the disease.</p></li>
<li><p>By the same logic, <em>if</em> the random person does not have the disease, we go down the bottom branch. The probability of the person incorrectly testing positive is 0.1.</p></li>
</ul>
<p>We decide to go down the top branch <em>if</em> our random person has the disease. We go down the bottom branch <em>if</em> they do not. This is called <strong>conditional probability</strong>. The probability of testing positive is <strong>dependent</strong> on whether the person has the disease.</p>
<p>How would you express this in statistical notation? <span class="math inline">\(P(A|B)\)</span> is the same thing as the probability of A <em>given</em> B. <span class="math inline">\(P(A|B)\)</span> essentially means the probability of A <em>if</em> we know for sure the value of B. Note that <span class="math inline">\(P(A|B)\)</span> is not the same thing as <span class="math inline">\(P(B|A)\)</span>.</p>
<p>In summary, we work with three main categories of probability distributions. First, p(A) is the probability distribution for event A. This is sometimes refered to as a <em>univariate</em> probability distribution because there is only one random variable. Second, p(A, B) is the joint probability distribution of A and B. Third, p(A | B) is the conditional probability distribution of A given that B has taken on a specific value. This is often written as p(A | B = b).</p>
</div>
</div>
<div id="list-columns-and-map-functions" class="section level2" number="5.3">
<h2>
<span class="header-section-number">5.3</span> List-columns and map functions<a class="anchor" aria-label="anchor" href="#list-columns-and-map-functions"><i class="fas fa-link"></i></a>
</h2>
<p>Before working with probability models, we need to expand our collection of R tricks by understanding list-columns and <code>map_*</code> functions. Recall that a list is different from an atomic vector. In atomic vectors, each element of the vector has one value. Lists, however, can contain vectors, and even more complex objects, as elements.</p>
<div class="sourceCode" id="cb549"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">4</span>, <span class="fl">16</span>, <span class="fl">9</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"A"</span>, <span class="st">"Z"</span><span class="op">)</span><span class="op">)</span>
<span class="va">x</span></code></pre></div>
<pre><code>## [[1]]
## [1]  4 16  9
## 
## [[2]]
## [1] "A" "Z"</code></pre>
<p><code>x</code> is a list with two elements. The first element is a numeric vector of length 3. The second element is a character vector of length 2. We use <code>[[]]</code> to extract specific elements.</p>
<div class="sourceCode" id="cb551"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span></code></pre></div>
<pre><code>## [1]  4 16  9</code></pre>
<p>There are a number of built-in R functions that output lists. For example, the <strong><em>ggplot</em></strong> objects you have been making store all of the plot information in lists. Any function that returns multiple values can be used to create a list output by wrapping that returned object with <code><a href="https://rdrr.io/r/base/list.html">list()</a></code>.</p>
<div class="sourceCode" id="cb553"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span>

<span class="co"># range() returns the min and max of the argument </span>

<span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>col_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> </code></pre></div>
<pre><code>## # A tibble: 1 × 1
##   col_1    
##   &lt;list&gt;   
## 1 &lt;dbl [2]&gt;</code></pre>
<p>Notice this is a 1-by-1 tibble with one observation, which is a list of one element. Voila! You have just created a <strong>list-column</strong>.</p>
<p><em>If a function returns multiple values as a vector, like <code><a href="https://rdrr.io/r/base/range.html">range()</a></code> does, you must use <code><a href="https://rdrr.io/r/base/list.html">list()</a></code> as a wrapper if you want to create a list-column.</em></p>
<p>A list column is a column of your data which is a <a href="https://adv-r.hadley.nz/vectors-chap.html#lists">list</a> rather than an atomic vector. As with stand-alone list objects, you can pipe to <code><a href="https://rdrr.io/r/utils/str.html">str()</a></code> to examine the column.</p>
<div class="sourceCode" id="cb555"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># tibble() is what we use to generate a tibble, it acts sort of like the mutate(), but mutate() needs a data frame to add new column, tibble can survive on itself.</span>
<span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>col_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## tibble [1 × 1] (S3: tbl_df/tbl/data.frame)
##  $ col_1:List of 1
##   ..$ : num [1:2] -1.01 1.42</code></pre>
<p>We can use <code>map_*</code> functions to both create a list-column and then, much more importantly, work with that list-column afterwards.</p>
<div class="sourceCode" id="cb557"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># .x is col_1 from tibble and ~ sum(.) is the formula</span>
<span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>col_1 <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>col_2 <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op">(</span><span class="va">col_1</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## tibble [1 × 2] (S3: tbl_df/tbl/data.frame)
##  $ col_1:List of 1
##   ..$ : num [1:2] -1.01 1.42
##  $ col_2: num 0.415</code></pre>
<p><code>map_*</code> functions, like <code><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl()</a></code> in this example, take two key arguments, <code>.x</code> (the data which will be acted on) and <code>.f</code> (the function which will act on this data). Here, <code>.x</code> is the data in <code>col_1</code>, which is a list-column. <code>.f</code> is the function <code><a href="https://rdrr.io/r/base/sum.html">sum()</a></code>. However, we can not simply write <code>map_dbl(col_1, sum)</code>. Instead, each use of <code>map_*</code> functions requires the use of a tilde — a <code>~</code> — to indicate the start of the function and the use of a dot — a <code>.</code> — to specify where the data goes in the function.</p>
<p><code>map_*</code> functions are a family of functions, with the suffix specifying the type of the object to be returned. <code><a href="https://purrr.tidyverse.org/reference/map.html">map()</a></code> itself returns a list. <code><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl()</a></code> returns a double. <code><a href="https://purrr.tidyverse.org/reference/map.html">map_int()</a></code> returns an integer. <code><a href="https://purrr.tidyverse.org/reference/map.html">map_chr()</a></code> returns a character, and so on.</p>
<p>To summarise <code>map</code> function and <code>map_</code>* functions could both convert an data (vector or list) with the specific denoted functions or formula you set, and always results in list we called the “list Column”. There are two arguments in the <code><a href="https://purrr.tidyverse.org/reference/map.html">map()</a></code> function as well as <code>map_*()</code> function the <code>.x</code> and <code>.f</code>, the <code>.x</code> and <code>.f</code> placed in the <code><a href="https://purrr.tidyverse.org/reference/map.html">map()</a></code> functions and <code>map_*()</code>functions like this <code>map(.x,.f)</code>, where <code>.x</code> could either be a list or a vector, and <code>.f</code> either be a direct function like <code>.f=mean</code>, or an formula like <code>.f= ~mean(.x)</code>, remember to put the <code>~</code> if you are using <code>.f</code> an formula, the difference between <code>map</code> and <code>map_*</code> function is when you know and want the outcome of the data to be specific data vector like (<code>double</code>, <code>logical</code>,<code>character</code>,<code>integer</code>) rather than an general <code>list</code> in <code><a href="https://purrr.tidyverse.org/reference/map.html">map()</a></code>, you can use <code>map_*</code> instead of <code>map</code> to organized your list column.</p>
<div class="sourceCode" id="cb559"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>ID <span class="op">=</span> <span class="fl">1</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>col_1 <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">ID</span>, <span class="op">~</span><span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>col_2 <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op">(</span><span class="va">col_1</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>col_3 <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">col_1</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/length.html">length</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>col_4 <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_chr</a></span><span class="op">(</span><span class="va">col_1</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://rdrr.io/r/utils/str.html">str</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<pre><code>## tibble [1 × 5] (S3: tbl_df/tbl/data.frame)
##  $ ID   : num 1
##  $ col_1:List of 1
##   ..$ : num [1:2] -1.45 1.31
##  $ col_2: num -0.143
##  $ col_3: int 2
##  $ col_4: chr "-0.142989"</code></pre>
<p>Consider a more detailed example:</p>
<div class="sourceCode" id="cb561"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># This simple example demonstrates the workflow which we will often follow.</span>
<span class="co"># Start by creating a tibble which will be used to store the results. (Or start</span>
<span class="co"># with a tibble which already exists and to which you will be adding more</span>
<span class="co"># columns.) It is often convenient to get all the code working with just a few</span>
<span class="co"># rows. Once it is working, we increase the number of rows to a thousand or</span>
<span class="co"># million or whatever we need.</span>

<span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">3</span><span class="op">)</span> |&gt; 
  
  <span class="co"># The big convenience is being able to store a list in each row of the tibble.</span>
  <span class="co"># Note that we are not using the value of ID in the call to rnorm(). (That is</span>
  <span class="co"># why we don't have a "." anywhere.) But we are still using ID as a way of</span>
  <span class="co"># iterating through each row; ID is keeping count for us, in a sense.</span>
  
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>draws <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">ID</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  
  <span class="co"># Each succeeding step of the pipe works with columns already in the tibble</span>
  <span class="co"># while, in general, adding more columns. The next step calculates the max</span>
  <span class="co"># value in each of the draw vectors. We use map_dbl() because we know that</span>
  <span class="co"># max() will returns a single number.</span>
  
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>max <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_dbl</a></span><span class="op">(</span><span class="va">draws</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  
  <span class="co"># We will often need to calculate more than one item from a given column like</span>
  <span class="co"># draws. For example, in addition to knowing the max value, we would like to</span>
  <span class="co"># know the range. Because the range is a vector, we need to store the result</span>
  <span class="co"># in a list column. map() does that for us automatically.</span>
  
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>min_max <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map</a></span><span class="op">(</span><span class="va">draws</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/range.html">range</a></span><span class="op">(</span><span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 3 × 4
##      ID draws        max min_max  
##   &lt;int&gt; &lt;list&gt;     &lt;dbl&gt; &lt;list&gt;   
## 1     1 &lt;dbl [10]&gt; 0.758 &lt;dbl [2]&gt;
## 2     2 &lt;dbl [10]&gt; 1.06  &lt;dbl [2]&gt;
## 3     3 &lt;dbl [10]&gt; 1.69  &lt;dbl [2]&gt;</code></pre>
<p>This flexibility is only possible via the use of list-columns and <code>map_*</code> functions. This workflow is extremely common. We start with an empty tibble, using ID to specify the number of rows. With that skeleton, each step of the pipe adds a new column, working off a column which already exists.</p>
</div>
<div id="two-models" class="section level2" number="5.4">
<h2>
<span class="header-section-number">5.4</span> Two models<a class="anchor" aria-label="anchor" href="#two-models"><i class="fas fa-link"></i></a>
</h2>
<!-- Consider the parallel structure of the 2-model, 3-model, and n-model case. First, we  begin by discussing how to create the joint distribution of possible models and possible experimental results. This is done by, first, assuming that one of the models is true and then, second, show the variation in the world which results. That is, even if we know for a fact that you do not have the disease, there is still a chance that you test will come back positive.

 Then, we create the joint distribution by doing that same thing for all possible models. (We show all this code.) The joint distribution is a tibble which we are happy to look at. It always has two columns: the first is the possible models (have disease) and the second is one possible result (test_positive) if that model is true. And that each possible model have at least 1,000 rows in the joint distribution.. -->
<!-- Having create the joint distribution, we graph it in two dimensions. (We show the code for that.) Then, we graph it in three dimensions with rayshader. (We have a rough movie.) Then, we take a "slice" of that joint distribution via rayshader (Have the movie but needs improvement). Move that slice around. Et cetera. Not sure how to do all that . . . Note that you can make rayshader objects interactive with rgl::rglwidget(). The ggral (sp?) package might also be useful (Did not use ggral yet to create rayshader 3D). -->
<!-- After rayshader, we then use the joint distribution to make two graphics, showing the posterior distribution for the model. The first is unnormalized and the second is normalized. In both cases, we begin with the joint distribution --- an object we have saved --- and then use filter to get our slice. Both graph and unromalized and normalized were made in 2D, could considered using rayshader/movie. -->
<p>The simplest possible setting for inference involves two models — meaning two possible states of the world — and two outcomes from an experiment. Imagine that there is a disease — <em>Probophobia</em>, an irrational fear of probability — which you either have or don’t have. We don’t know if you have the diseases, but we do assume that there are only two possibilities.</p>
<p>We also have a test which is 99% accurate when given to a person who has <em>Probophobia</em>. Unfortunately, the test is only 50% accurate for people who do not have <em>Probophobia</em>. In this experiment, there only two possible outcomes: a positive and a negative result on the test.</p>
<p>Question: <em>If you test positive, what is the probability that you have Probophobia?</em></p>
<p>More generally, we are estimating a <em>conditional probability</em>. Conditional on the outcome of a postive test, what is the probability that you have Probophobia? Mathematically, we want:</p>
<p><span class="math display">\[ P(\text{Probophobia | Test = Postive} ) \]</span></p>
<p>To answer this question, we need to use the tools of joint and conditional probability from earlier in the Chapter. We begin by building, by hand, the joint distribution of the possible models (you have the Probophobia or you do not) and of the possible outcomes (you test positive or negative). Building the joint distribution involves <em>assuming</em> that each model is true and then creating the distribution of outcomes which might occur if that assumption is true.</p>
<p>For example, assume you have Probophobia. There is then a 50% chance that you test positive and a 50% chance you test negative. Similarly, if we assume that the second model is true — that you don’t have Probophobia — then there is 1% chance you test positive and a 99% you chance negative. Of course, for you (or any individual) we do not know for sure what is happening. We do not know if you have the disease. We do not know what your test will show. But we can use these relationships to construct the joint distribution.</p>
<!-- DK: Redo this analysis, and perhaps other similar examples below. First, column of tibble is the state of the world. Or list of all possible models. In this case, this would be `have_disease` which should be either TRUE or FALSE.  -->
<div class="sourceCode" id="cb563"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Pipes generally start with tibbles, so we start with a tibble which just</span>
<span class="co"># includes an ID variable. We don't really use ID. It is just handy for getting</span>
<span class="co"># organized. We call this object `jd_disease`, where the `jd` stands for</span>
<span class="co"># joint distribution.</span>

<span class="va">sims</span> <span class="op">&lt;-</span> <span class="fl">10000</span>

<span class="va">jd_disease</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">sims</span>, have_disease <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span>, <span class="fl">5000</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>positive_test <span class="op">=</span>
           <span class="fu"><a href="https://dplyr.tidyverse.org/reference/if_else.html">if_else</a></span><span class="op">(</span><span class="va">have_disease</span>,
                   <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">have_disease</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.99</span><span class="op">)</span><span class="op">)</span>,
                   <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">have_disease</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>



<span class="va">jd_disease</span></code></pre></div>
<pre><code>## # A tibble: 10,000 × 3
##       ID have_disease positive_test
##    &lt;int&gt; &lt;lgl&gt;                &lt;int&gt;
##  1     1 TRUE                     1
##  2     2 FALSE                    1
##  3     3 TRUE                     1
##  4     4 FALSE                    1
##  5     5 TRUE                     1
##  6     6 FALSE                    0
##  7     7 TRUE                     1
##  8     8 FALSE                    1
##  9     9 TRUE                     1
## 10    10 FALSE                    0
## # … with 9,990 more rows</code></pre>
<p>The first step is to simply create an tibble that consists of the simulated data we need to plot our distribution. Keep in mind that in the setting we have two different probabilities and they are completely separate from each other and we want to keep the two probabilities and the disease results in two and only two columns so that we can graph using the <code><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot()</a></code> function. And that’s why we used the <code>rep</code> and <code>seq</code> functions when creating the table, we used the <code>seq</code> function to set the sequence we wants, in this case is only two numbers, 0.01 (99% accuracy for testing negative if no disease, therefore 1% for testing positive if no disease) and 0.5 (50% accuracy for testing positive/negative if have disease), then we used the <code>rep</code> functions to repeat the process 10,000 times for each probability, in total 20,000 times. Note that this number “20,000” also represent the number of observations in our simulated data, we simulated 20,000 results from testing, where 10,000 results from the have-disease group and 10,000 for the no-disease group, we often use the capital N to represent the population, in this simulated data <span class="math inline">\(N=20,000\)</span>.</p>
<p>Plot the joint distribution:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-403-1.png" width="100%"></div>
<p>Below is a joint distribution displayed in 3D. Instead of using the “jitter” feature in R to unstack the dots, we are using a 3D plot to visualize the number of dots in each box. The number of people who correctly test negative is far greater than of the other categories. The 3D plot shows the total number of cases for each section (True positive, True negative, False positive, False negative),the 3D bar coming from those combinations. Now,pay attention to the two rows of the 3D graph, if you trying to add up the length of the 3D bar for the top two sections and the bottom two sections, they should be equal to each other, where each have 10,000 case. This is because we simulate the experience in two independent and separate world one in the have-disease world and one in the no-disease world.</p>
<!-- DK: Insert the sliced rayshader distribution here, and discuss. Then, below, we do the same thing by hand. Then, use this text: -->
<!-- If we zoom in on the plot, FIX THIS people who tested positive have the disease and FIX THIS who tested positive do not have the disease. In this case, we are focusing on one slice of the probability distribution where the test result was positive. There are two disease outcomes: positive or negative. By isolating a section, we are looking at a conditional distribution. Conditional on a positive test, you can visualize the likelihood of actually having the disease versus not. -->
<p>This Section is called “Two Models” because, for each person, <em>there are two possible states of the world: have the disease or not have the disease.</em> By assumption, there are no other outcomes. We call these two possible states of the world “models,” even though they are very simple models.</p>
<p>In addition to the two models, we have two possible results of our experiment on a given person: test positive or test negative. Again, this is an assumption. We do not allow for any other outcome. In coming sections, we will look at more complex situations where we consider more than two models and more than two possible results of the experiment. In the meantime, we have built the <em>unnormalized joint distribution for models and results</em>. This is a key point! Look back earlier in this Chapter for discussions about both unnormalized distributions and joint distributions.</p>
<p>We want to analyze these plots by looking at different slices. For instance, let’s say that you have tested positive for the disease. Since the test is not always accurate, you cannot be 100% certain that you have it. We isolate the slice where the test result equals 1 (meaning positive).</p>
<div class="sourceCode" id="cb565"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">jd_disease</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">positive_test</span> <span class="op">==</span> <span class="fl">1</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 7,484 × 3
##       ID have_disease positive_test
##    &lt;int&gt; &lt;lgl&gt;                &lt;int&gt;
##  1     1 TRUE                     1
##  2     2 FALSE                    1
##  3     3 TRUE                     1
##  4     4 FALSE                    1
##  5     5 TRUE                     1
##  6     7 TRUE                     1
##  7     8 FALSE                    1
##  8     9 TRUE                     1
##  9    11 TRUE                     1
## 10    12 FALSE                    1
## # … with 7,474 more rows</code></pre>
<p><strong>Most people test positive are infected</strong> This is a result for common diseases like cold. We can easily create an unnormalized conditional distribution with:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-406-1.png" width="100%"></div>
<p><em><code><a href="https://dplyr.tidyverse.org/reference/filter.html">filter()</a></code> transforms a joint distribution into a conditional distribution.</em></p>
<p>Turn this unnormalized distribution into a posterior probability distribution:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-407-1.png" width="100%"></div>
<p>If we zoom in on the plot, about 70% of people who tested positive have the disease and 30% who tested positive do not have the disease. In this case, we are focusing on one slice of the probability distribution where the test result was positive. There are two disease outcomes: positive or negative. By isolating a section, we are looking at a conditional distribution. Conditional on a positive test, you can visualize the likelihood of actually having the disease versus not.</p>
<p>Now recalled the question we asked at the start of the session:
<em>If you test positive, what is the probability that you have Probophobia?</em></p>
<p>By looking at the posterior graph we just create, we can answer this question easily:
<em>With a positive test, you can be almost 70% sure that you have Probophobia, however there is a good chance about 30% that you receive a false positive, so don’t worry too much there is still about a third of hope that you get the wrong result</em></p>
<p>Now let’s consider the manipulation of this posterior, here is another question.
Question : <em>10 people walks up to testing center, 5 of them tested negative, 5 of them tested positive, what is the probability of at least 6 people is actually healthy? </em></p>
<div class="sourceCode" id="cb567"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>test <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="fl">100000</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person1 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person2 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person3 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person4 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person5 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.3</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person6 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person7 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person8 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person9 <span class="op">=</span>  <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>person10 <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">test</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">1</span>, p <span class="op">=</span> <span class="fl">0.7</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/select.html">select</a></span><span class="op">(</span><span class="op">!</span><span class="va">test</span><span class="op">)</span> |&gt; 
  
<span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>sum <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/colSums.html">rowSums</a></span><span class="op">(</span><span class="fu"><a href="https://dplyr.tidyverse.org/reference/across.html">across</a></span><span class="op">(</span><span class="va">person1</span><span class="op">:</span><span class="va">person10</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  
<span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">sum</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes_eval.html">after_stat</a></span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,
                 binwidth <span class="op">=</span> <span class="fl">1</span>,
                   color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">10</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> 
                         <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/percent_format.html">percent_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span>  </code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-408-1.png" width="100%"></div>
<!-- DK: Insert a use of this posterior? How many positive tests before you have at least 10 sick people? -->
<p>This Stat 110 Animations video does a really good job of explaining similar concepts.</p>
<iframe src="https://www.youtube.com/embed/by3_weGwnMg?showcase=0" width="100%" height="400px" data-external="1">
</iframe>
</div>
<div id="three-models" class="section level2" number="5.5">
<h2>
<span class="header-section-number">5.5</span> Three models<a class="anchor" aria-label="anchor" href="#three-models"><i class="fas fa-link"></i></a>
</h2>
<!-- Handy? jd_marbles |> filter(in_bag == 1) |> group_by(in_sample) |> count() -->
<!-- DK: Should this be in terms of p or number of white marbles or both? -->
<div class="inline-figure"><img src="05-probability/images/marble.jpg" width="100%"></div>
<p>Imagine that your friend gives you a bag with two marbles. There could either be two white marbles, two black marbles, or one of each color. Thus, the bag could contain 0% white marbles, 50% white marbles, or 100% white marbles. Respectively, the proportion, <span class="math inline">\(p\)</span>, of white marbles could be 0, 0.5, or 1.</p>
<p>Question: <em>What is the chance of the bag contains exactly two white marbles, given that when we selected the marbles three times, everytime we select a white marble?</em></p>
<p><span class="math display">\[ P(\text{2 White Marbles in bag | White Marbles Sampled = 3} ) \]</span>
Just as during the <em>Probophobia</em> models, in order to answer this question, we need to start up with the simulated data and then graphing out the joint distribution of this sinerio because we need to considered all possible outcomes of this model, and then based on the joint distribution we can slice out the the part we want (Conditional distribution) in the end making an posterior graph as well as normalizing it to see the probability.</p>
<p>Step 1: Simulate the data into an tibble</p>
<p>Let’s say you take a marble out of the bag, record whether it’s black or white, then return it to the bag. You repeat this three times, observing the number of white marbles you see out of three trials. You could get three whites, two whites, one white, or zero whites as a result of this trial. We have three models (three different proportions of white marbles in the bag) and four possible experimental results. Let’s create 3,000 draws from this joint distribution:</p>
<div class="sourceCode" id="cb568"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># Create the joint distribution of the number of white marbles in the bag</span>
<span class="co"># (in_bag) and the number of white marbles pulled out in the sample (in_sample),</span>
<span class="co"># one-by-one. in_bag takes three possible values: 0, 1 and 2, corresponding to</span>
<span class="co"># zero, one and two white marbles potentially in the bag.</span>

<span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">3</span><span class="op">)</span>
<span class="va">sims</span> <span class="op">&lt;-</span> <span class="fl">10000</span>

<span class="co"># We also start off with a tibble. It just makes things easier</span>

<span class="va">jd_marbles</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">sims</span><span class="op">)</span> |&gt; 
  
  <span class="co"># For each row, we (randomly!) determine the number of white marbles in the</span>
  <span class="co"># bag. We do not know why the `as.integer()` hack is necessary. Shouldn't</span>
  <span class="co"># `map_int()` automatically coerce the result of `sample()` into an integer?</span>
  
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>in_bag <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">ID</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/base/integer.html">as.integer</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span>, 
                                                  size <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  
  <span class="co"># Depending on the number of white marbles in the bag, we randomly draw out 0,</span>
  <span class="co"># 1, 2, or 3 white marbles in our experiment. We need `p = ./2` to transform</span>
  <span class="co"># the number of white marbles into the probability of drawing out a white</span>
  <span class="co"># marble in a single draw. That probability is either 0%, 50% or 100%.</span>
  
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>in_sample <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">in_bag</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, 
                                              size <span class="op">=</span> <span class="fl">3</span>, 
                                              p <span class="op">=</span> <span class="va">.</span><span class="op">/</span><span class="fl">2</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> 

<span class="va">jd_marbles</span></code></pre></div>
<pre><code>## # A tibble: 10,000 × 3
##       ID in_bag in_sample
##    &lt;int&gt;  &lt;int&gt;     &lt;int&gt;
##  1     1      0         0
##  2     2      1         3
##  3     3      2         3
##  4     4      1         1
##  5     5      2         3
##  6     6      2         3
##  7     7      1         0
##  8     8      2         3
##  9     9      0         0
## 10    10      1         2
## # … with 9,990 more rows</code></pre>
<p>Step 2: Plot the joint distribution:</p>
<div class="sourceCode" id="cb570"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># The distribution is unnormalized. All we see is the number of outcomes in each</span>
<span class="co"># "bucket." Although it is never stated clearly, we are assuming that there is</span>
<span class="co"># an equal likelihood of 0, 1 or 2 white marbles in the bag.</span>

<span class="va">jd_marbles</span> |&gt;
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">in_sample</span>, y <span class="op">=</span> <span class="va">in_bag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_jitter.html">geom_jitter</a></span><span class="op">(</span>alpha <span class="op">=</span> <span class="fl">0.5</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Black and White Marbles"</span>,
         subtitle <span class="op">=</span> <span class="st">"More white marbles in bag mean more white marbles selected"</span>,
         x <span class="op">=</span> <span class="st">"White Marbles Selected"</span>,
         y <span class="op">=</span> <span class="st">"White Marbles in the Bag"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-412-1.png" width="100%"></div>
<p>Here is the 3D visualization:</p>
<p>The y-axes of both the scatterplot and the 3D visualization are labeled “Number of White Marbles in the Bag.” <em>Each value on the y-axis is a model, a belief about the world.</em> For instance, when the model is 0, we have no white marbles in the bag, meaning that none of the marbles we pull out in the sample will be white.</p>
<p>Now recalls the question, we essentially only care about the fourth column in the joint distribution (x-axis=3) because the question is asking us to create a conditional distribution <em>given</em> that fact that 3 marbles were selected. Therefore, we could isolate the slice where the result of the simulation involves three white marbles and zero black ones. Here is the unnormalized probability distribution.</p>
<p>Step 3: Plot the unnormalized conditional distribution.</p>
<div class="sourceCode" id="cb571"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># The key step is the filter. Creating a conditional distribution from a joint</span>
<span class="co"># distribution is the same thing as filtering that joint distribution for a</span>
<span class="co"># specific value. A conditional distribution is a "slice" of the joint</span>
<span class="co"># distribution, and we take that slice with filter().</span>

<span class="va">jd_marbles</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">in_sample</span> <span class="op">==</span> <span class="fl">3</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">in_bag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span>binwidth <span class="op">=</span> <span class="fl">0.5</span>, color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Unnormalized Conditional Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Number of white marbles in bag given that three were selected in the sample"</span>,
         x <span class="op">=</span> <span class="st">"Number of White Marbles in the Bag"</span>,
         y <span class="op">=</span> <span class="st">"Count"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-414-1.png" width="100%"></div>
<p>Step 4: Plot the normalize posterior distribution.
Next, let’s normalize the distribution.</p>
<div class="sourceCode" id="cb572"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">jd_marbles</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">in_sample</span> <span class="op">==</span> <span class="fl">3</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">in_bag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes_eval.html">after_stat</a></span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, 
                   binwidth <span class="op">=</span> <span class="fl">0.5</span>, 
                   color <span class="op">=</span> <span class="st">"white"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Posterior Probability Distribution"</span>,
         subtitle <span class="op">=</span> <span class="st">"Number of white marbles in bag given that three were selected in the sample"</span>,
         x <span class="op">=</span> <span class="st">"Number of White Marbles in the Bag"</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/coord_cartesian.html">coord_cartesian</a></span><span class="op">(</span>xlim <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>breaks <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> 
                         <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/percent_format.html">percent_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-415-1.png" width="100%"></div>
<p>This plot makes sense because when all three marbles you draw out of the bag are white, there is a pretty good chance that there are no black marbles in the bag. But you can’t be certain! It is possible to draw three white even if the bag contains one white and one black. However, it is impossible that there are zero white marbles in the bag.</p>
<p>Lastly let’s answer the question:
<em>What is the chance of the bag contains exactly two white marbles, given that when we selected the white marbles three times, everytime we select a white marble?</em></p>
<p>Answer:
<em>As the Posterior Probability Distribution shows (x-axis=2), the chance of the bag contains exactly two white marbles given that we select 3 white marbles out of three tries is about 85%.</em></p>
</div>
<div id="n-models" class="section level2" number="5.6">
<h2>
<span class="header-section-number">5.6</span> N models<a class="anchor" aria-label="anchor" href="#n-models"><i class="fas fa-link"></i></a>
</h2>
<!-- 5 a) Now go on to Rethinking approach. I think that chapter 2 is just genius. Bayesian is really just counting. Maybe we do a very similar example to what he does? Maybe different? I am still pondering this myself. I think that there is a deep relationship here. In the simple Bayes rule decision trees, we know all the probabilities. But what if we don't? Instead, we get to observe lots of data (which are counts!) and then, from that data, figure out the probabilities. (Note that Rethinking does not talk like this --- after all, we know all the probabilities since each marble has a 20% chance of being drawn --- but I think it is implicit in his approach.) Key issue: Can we connect this in a sensible way to Bayesian scatterplot. There is always the data and the model and the relationship between the two. (And "the model" means, mainly, the parameter estimates thereof.) Tell me the data, and I will tell you the model. Tell me the model, and I will tell you the model. -->
<!-- Note the connection between the marbles from Rethinking and the Bayesian scatterplot. In figure 2.2 in Rethinking represents the model where p = 0.25, where p is the proportion of blue marbles in the total collection. The y-axis models would be labeled with p = 0, 0.25, 0.5, 0.75, and 1. With the tree marble diagram in figure 2.2, we would be taking random samples with 3 marbles. The number of blue marbles we get each time would be plotted along p = 0.25. This is another example of model on the y-axis and data on the x-axis. -->
<!-- DK: Should we cut out p = 0 and p = 1 as too annoying to deal with? -->
<div class="inline-figure"><img src="05-probability/images/heads.jpg" width="100%"></div>
<p>Assume that there is a coin with <span class="math inline">\(\rho_h\)</span>. We guarantee that there are only 11 possible values of <span class="math inline">\(\rho_h\)</span>: <span class="math inline">\(0, 0.1, 0.2, ..., 0.9, 1\)</span>. In other words, there are 11 possible models, 11 things which might be true about the world. This is just like situations we have previously discussed, except that there are more models to consider.</p>
<p>We are going to run an experiment in which you flip the coin 20 times and record the number of heads. What does this result tell you about the value of <span class="math inline">\(\rho_h\)</span>? Ultimately, we will want to calculate a posterior distribution of <span class="math inline">\(\rho_h\)</span>, which is written as p(<span class="math inline">\(\rho_h\)</span>).</p>
<p>Question: <em>What is the probability of getting exactly 8 heads out of 20 tosses?</em></p>
<p>To start, it is useful to consider all the things which might happen if, for example, <span class="math inline">\(\rho_h = 0.4\)</span>. Fortunately, the R functions for simulating random variables makes this easy.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-417-1.png" width="100%"></div>
<p>First, notice that many different things can happen! Even if we <em>know</em>, for certain, that <span class="math inline">\(\rho_h = 0.4\)</span>, many outcomes are possible. Life is remarkably random. Second, the most likely result of the experiment is 8 heads, as we would expect. Third, we have transformed the raw counts of how many times each total appeared into a probability distribution. Sometimes, however, it is convenient to just keep track of the raw counts. The shape of the figure is the same in both cases.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-418-1.png" width="100%"></div>
<p>Either way, the figures show what would have happened if that model — that <span class="math inline">\(\rho_h = 0.4\)</span> — were true.</p>
<p>We can do the same thing for all 11 possible models, calculating what would happen if each of them were true. This is somewhat counterfactual since only one of them can be true. Yet this assumption does allow us to create the <em>joint distribution</em> of <em>models which might be true</em> and of <em>data which our experiment might generate</em>. Let’s simplify this is p(models, data), although you should keep the precise meaning in mind.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-419-1.png" width="100%"></div>
<p>Here is the 3D version of the same plot.</p>
<p>In both of these diagrams, we see 11 models and 21 outcomes. We don’t really care about the p(<span class="math inline">\(models\)</span>, <span class="math inline">\(data\)</span>), the joint distribution of the models-which-might-be-true and the data-which-our-experiment-might-generate. Instead, we want to estimate <span class="math inline">\(p\)</span>, the unknown parameter which determines the probability that this coin will come up heads when tossed. The joint distribution alone can’t tell us that. We <em>created</em> the joint distribution before we had even conducted the experiment. It is our creation, a tool which we use to make inferences. Instead, we want the conditional distribution, p(<span class="math inline">\(models\)</span> | <span class="math inline">\(data = 8\)</span>). We have the results of the experiment. What do those results tell us about the probability distribution of <span class="math inline">\(p\)</span>?</p>
<p>To answer this question, we simply take a vertical <em>slice</em> from the joint distribution at the point of the x-axis corresponding to the results of the experiment.</p>
<p>This animation shows what we want to do with joint distributions. We take a slice (the red one), isolate it, rotate it to look at the conditional distribution, normalize it (change the values along the current z-axis from counts to probabilities), then observe the resulting posterior.</p>
<!-- 

TW: I tried to recreate the GIF below in rayshader, but failed. For those bold enough to try, the process 
to create it would be as follows (problem described at the end):


1. Create a dataframe with three columns: x, y and z. These will be the coordinates. 
   Note that you need to cover every possible combination of x and y-values, and 
   every such combination must have a z-value. Thus, the dataframe should have 
   3 * [(#x-values)*(#values)] observations. Creating this by hand is a tedious process, 
   but if you are using the same series of z-values over and over again, MS Excel might 
   be helpful. 
   If you want to save time, check out the file Values.xlsx in primer/05-probability. It
   contains a dataframe I created, but it does not have the exact same dimensions as the plot 
   in the GIF.
   
   
2. Create a 2D plot like this and and save it as an object.
    
plot <-- ggplot(df, aes(x, y, color = z)) +
          geom_point() +
          theme(legend.position = "none")
   
   
3. Turn it into a 3D plot. Use the following code. Only the first
   argument is required, you may adjust the rest.

plot_gg(plot,
        width = 3.5,
        zoom = 0.65,
        theta = 25,
        phi = 30,
        sunangle = 225,
        soliddepth = -50,
        windowsize = c(2048,1536))


4. If you installed xquartz, and window named "RGL Device" with the plot 
   should have opened on your machine. Tilt the plot in the desired position.
   Then, run this command to create a snapshot:
   
render_snapshot()

   Congrats, you now have a single snapshot. However, keep in mind that in order to 
   create a GIF, you need a series of snapshots that can be rendered into a GIF. This
   means you will have to repeat the above process for every possible perspective/plot 
   seen in below. And since the GIF consist of different plots, you must not only change
   the perspective, but also the plot itself when creating all those snapshots. As I see it, 
   there are four different plots that would need to be created:
    
    - "edge view" and all blue (initial view / one snapshot)
    - "edge view" and one distribution red (one snapshot)
    - "edge view" and all but red distribution flat (one snapshot) 
    - shift to a frontal 2D-like perspective (many snapshots)
   
   The last step can (and should) be automated. This involves writing a loop that changes the 
   view on the plot just a little bit, creates a snapshot, moves on to the next position, creates
   another snapshot, and so on. This is not as hard as it seems, and a basic example of this can
   be found here https://www.tylermw.com/a-step-by-step-guide-to-making-3d-maps-with-satellite-imagery-in-r/
   (scroll down to the last image).
   

5. Once you have created all the snapshots the GIF will consist of, make sure their names reflect
   the order in which they should be displayed. For example, "plot1.png", "plot2.png" and so on. If
   you write the loop the right way, you may only have to rename the first three snapshots created 
   manually. See the link above for details.
   Finally, you can put it all together. First, run this command in R to close the "RGL Device" window:

rgl::rgl.close()

  Next, run this command in the TERMINAL. Make sure that you are in the right working directory and that 
  you have ffmpeg installed. The third part defines the framerate per second, the example below uses 60. 
  The fifth part must be named like your snapshots, followed by "%d.png". The last part is the name of the 
  mp4 file, or the GIF, and can be named anything you like.

system("ffmpeg -framerate 60 -i plot%d.png -pix_fmt yuv420p plot_gif.mp4")
   
   
-----------------------
   
The Problem:

I don't know how to create a 3D plot with rayshader and gpplot AND manually defined colors. Specifically, 
I didn't manage to create the 3D plot with one red distribution surrounded by blue distributions. The issue 
seems to be that rayshader uses the "color" aesthetic to make the z-axis. If you try to change the color of 
a range of observations to red/blue, the z-values of these observations will be messed up.  


-->
<div class="inline-figure"><img src="05-probability/animations/color_red_combo.gif"></div>
<p>This is the only part of the joint distribution that we care about. We aren’t interested in what the object looks like where, for example, the number of heads is 11. That portion is irrelevant because we observed 8 heads, not 11. By using the filter function on the simulation tibble we created, we can conclude that there are a total of 465 times in our simulation in which 8 heads were observed.</p>
<p>As we would expect, most of the time when 8 coin tosses came up heads, the value of <span class="math inline">\(p\)</span> was 0.4. But, on numerous occasions, it was not. It is quite common for a value of <span class="math inline">\(p\)</span> like 0.3 or 0.5 to generate 8 heads. Consider:</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-421-1.png" width="100%"></div>
<p>Yet this is a distribution of raw counts. It is an unnormalized density. To turn it into a proper probability density (i.e., one in which the sum of the probabilities across possible outcomes sums to one) we just divide everything by the total number of observations.</p>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-422-1.png" width="100%"></div>
<p>Solution:</p>
<p><em>The most likely value of <span class="math inline">\(\rho_h\)</span> is 0.4, as before. But, it is much more likely that <span class="math inline">\(p\)</span> is either 0.3 or 0.5. And there is about an 8% chance that <span class="math inline">\(\rho_h \ge 0.6\)</span>.</em></p>
<p>You might be wondering: what is the use of a model? Well, let’s say we toss the coin 20 times and get 8 heads again. Given this result, we can ask: <em>What is the probability that future samples of 20 flips will result in 10 or more heads?</em></p>
<p>There are three main ways you could go about solving this problem with simulations.</p>
<p>The first <em>wrong</em> way to do this is assuming that <span class="math inline">\(\rho_h\)</span> is certain because we observed 8 heads after 20 tosses. We would conclude that 8/20 gives us 0.4. The big problem with this is that you are ignoring your uncertainty when estimating <span class="math inline">\(\rho_h\)</span>. This would lead us to the following code.</p>
<div class="sourceCode" id="cb573"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">sims</span> <span class="op">&lt;-</span> <span class="fl">10000000</span>

<span class="va">odds</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>sim_ID <span class="op">=</span> <span class="fl">1</span><span class="op">:</span><span class="va">sims</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>heads <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">sim_ID</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">20</span>, p <span class="op">=</span> <span class="fl">.4</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>above_ten <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/if_else.html">if_else</a></span><span class="op">(</span><span class="va">heads</span> <span class="op">&gt;=</span> <span class="fl">10</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span>

<span class="va">odds</span></code></pre></div>
<pre><code>## # A tibble: 10,000,000 × 3
##    sim_ID heads above_ten
##     &lt;int&gt; &lt;int&gt; &lt;lgl&gt;    
##  1      1    10 TRUE     
##  2      2     5 FALSE    
##  3      3     2 FALSE    
##  4      4    10 TRUE     
##  5      5     5 FALSE    
##  6      6    10 TRUE     
##  7      7     7 FALSE    
##  8      8    11 TRUE     
##  9      9     9 FALSE    
## 10     10     9 FALSE    
## # … with 9,999,990 more rows</code></pre>
<div class="sourceCode" id="cb575"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">odds</span> |&gt;
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x<span class="op">=</span><span class="va">heads</span>,fill<span class="op">=</span><span class="va">above_ten</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
           <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes_eval.html">after_stat</a></span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,bins <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_fill_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'grey50'</span>, <span class="st">'red'</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Posterior Probability Distribution (Wrong Way)"</span>,
         subtitle <span class="op">=</span> <span class="st">"Number of heads in 20 tosses"</span>,
         x <span class="op">=</span> <span class="st">"Number of heads"</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span>,
         fill <span class="op">=</span> <span class="st">"Above ten heads"</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/comma.html">number_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/percent_format.html">percent_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure"><img src="book_temp_files/figure-html/unnamed-chunk-424-1.png" width="100%"></div>
<p>Using this Posterior distribution derived from the (wrong way) simulated data, the probability results in 10 or more head is</p>
<div class="sourceCode" id="cb576"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">odds</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>success <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">above_ten</span><span class="op">)</span><span class="op">/</span><span class="va">sims</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##   success
##     &lt;dbl&gt;
## 1   0.245</code></pre>
<p>about 24.5%.</p>
<p>The second method involves sampling the whole posterior distribution vector we previously created. This would lead to the following correct code.</p>
<div class="sourceCode" id="cb578"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">p_draws</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/rep.html">rep</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">1</span>, <span class="fl">0.1</span><span class="op">)</span>, <span class="fl">1000</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>heads <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">p</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">20</span>, p <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/filter.html">filter</a></span><span class="op">(</span><span class="va">heads</span> <span class="op">==</span> <span class="fl">8</span><span class="op">)</span>
  
<span class="va">odds_2nd</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://tibble.tidyverse.org/reference/tibble.html">tibble</a></span><span class="op">(</span>p <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sample.html">sample</a></span><span class="op">(</span><span class="va">p_draws</span><span class="op">$</span><span class="va">p</span>, size <span class="op">=</span> <span class="va">sims</span>, replace <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span><span class="op">)</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>heads <span class="op">=</span> <span class="fu"><a href="https://purrr.tidyverse.org/reference/map.html">map_int</a></span><span class="op">(</span><span class="va">p</span>, <span class="op">~</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">rbinom</a></span><span class="op">(</span>n <span class="op">=</span> <span class="fl">1</span>, size <span class="op">=</span> <span class="fl">20</span>, p <span class="op">=</span> <span class="va">.</span><span class="op">)</span><span class="op">)</span><span class="op">)</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span><span class="op">(</span>above_ten <span class="op">=</span> <span class="fu"><a href="https://dplyr.tidyverse.org/reference/if_else.html">if_else</a></span><span class="op">(</span><span class="va">heads</span> <span class="op">&gt;=</span> <span class="fl">10</span>, <span class="cn">TRUE</span>, <span class="cn">FALSE</span><span class="op">)</span><span class="op">)</span> 

<span class="va">odds_2nd</span></code></pre></div>
<pre><code>## # A tibble: 10,000,000 × 3
##        p heads above_ten
##    &lt;dbl&gt; &lt;int&gt; &lt;lgl&gt;    
##  1   0.4     7 FALSE    
##  2   0.3     8 FALSE    
##  3   0.5    13 TRUE     
##  4   0.4    10 TRUE     
##  5   0.4     6 FALSE    
##  6   0.5     8 FALSE    
##  7   0.5     9 FALSE    
##  8   0.5    12 TRUE     
##  9   0.5    10 TRUE     
## 10   0.4     8 FALSE    
## # … with 9,999,990 more rows</code></pre>
<div class="sourceCode" id="cb580"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">odds_2nd</span> |&gt;
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">heads</span>,fill <span class="op">=</span> <span class="va">above_ten</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
           <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_histogram.html">geom_histogram</a></span><span class="op">(</span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>y <span class="op">=</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes_eval.html">after_stat</a></span><span class="op">(</span><span class="va">count</span><span class="op">/</span><span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">count</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>,bins <span class="op">=</span> <span class="fl">50</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_manual.html">scale_fill_manual</a></span><span class="op">(</span>values <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">'grey50'</span>, <span class="st">'red'</span><span class="op">)</span><span class="op">)</span><span class="op">+</span>
  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>title <span class="op">=</span> <span class="st">"Posterior Probability Distribution (Right Way)"</span>,
         subtitle <span class="op">=</span> <span class="st">"Number of heads in 20 tosses"</span>,
         x <span class="op">=</span> <span class="st">"Number of heads"</span>,
         y <span class="op">=</span> <span class="st">"Probability"</span>,
         fill <span class="op">=</span> <span class="st">"Above ten heads"</span><span class="op">)</span> <span class="op">+</span> 
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_x_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/comma.html">number_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/scale_continuous.html">scale_y_continuous</a></span><span class="op">(</span>labels <span class="op">=</span> <span class="fu">scales</span><span class="fu">::</span><span class="fu"><a href="https://scales.r-lib.org/reference/percent_format.html">percent_format</a></span><span class="op">(</span>accuracy <span class="op">=</span> <span class="fl">1</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span>
    <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_classic</a></span><span class="op">(</span><span class="op">)</span></code></pre></div>
<div class="inline-figure">
<img src="book_temp_files/figure-html/unnamed-chunk-427-1.png" width="100%">
Using this Posterior distribution derived from the (right way 1st) simulated data, the probability results in 10 or more head is</div>
<div class="sourceCode" id="cb581"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">odds_2nd</span> |&gt;
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>success <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/sum.html">sum</a></span><span class="op">(</span><span class="va">above_ten</span><span class="op">)</span><span class="op">/</span><span class="va">sims</span><span class="op">)</span></code></pre></div>
<pre><code>## # A tibble: 1 × 1
##   success
##     &lt;dbl&gt;
## 1   0.351</code></pre>
<p>about 32.8%</p>
<p>As you may have noticed, if you calculated the value using the first method, you would believe that getting 10 or more heads is less likely than it really is. If you were to run a casino based on these assumptions, you will lose all your money. It is very important to be careful about the assumptions you are making. We tossed a coin 20 times and got 8 heads. However, you would be wrong to assume that <span class="math inline">\(\rho_h\)</span> = 0.4 just based on this result.</p>
<!-- ## Testing is evil -->
<!-- Introduce concepts like the null model, testing, and p-values. Connect to permutation tests from chapter 3.  Side note quotation: "Amateurs test. Professionals summarize." Maybe we should pick an example in which the number of heads is low enough to provide some reasonable evidence against p = 0.5. -->
<!-- In some fields, it is common to want to test a specific hypothesis. Consider the hypothesis that the coin is fair, i.e., that $p = 0.5$. Does the data we have support or reject that hypothesis? (Be wary that $p$ is both used for the probability of a head and the $p$-value of a hypothesis test.) -->
<!-- Not really interested in that exact test except in toy scenarios. -->
<!-- Difference between 0.04 and 0.06 is rarely significant. And is hardly ever a good reason to decide X over Y. -->
<!-- Infinite models might be an infinite urn. What is the proportion p of red beads in the urn? Assume you are sampling 25 beads from the urn. What is posterior for p if your draw out 5 reds? Inifite models just means setting 100,000 (or some large number) possible values for p when creating the joint distribution.  -->
</div>
<div id="working-with-probability-distributions" class="section level2" number="5.7">
<h2>
<span class="header-section-number">5.7</span> Working with probability distributions<a class="anchor" aria-label="anchor" href="#working-with-probability-distributions"><i class="fas fa-link"></i></a>
</h2>
<!-- DK: Does this really belong here? Maybe at the end? -->
<p>A probability distribution is not always easy to work with. It is a complex object. And, in many contexts, we don’t really care about all that complexity. So, instead of providing the full probability distribution, we often just use a summary measure, a number or two or three which captures those aspects of the entire distribution which are relevant to the matter at hand. Let’s explore these issues using the 538 posterior probability distribution, as of August 13, 2020, for the number of electoral votes which will be won by Joe Biden. Here is a tibble with 1,000,000 draws from that distribution:</p>
<div class="sourceCode" id="cb583"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="va">draws</span></code></pre></div>
<pre><code>## # A tibble: 1,000,000 × 2
##       ID electoral_votes
##    &lt;int&gt;           &lt;int&gt;
##  1     1             210
##  2     2             277
##  3     3             227
##  4     4             397
##  5     5             378
##  6     6             428
##  7     7             350
##  8     8             385
##  9     9             325
## 10    10             463
## # … with 999,990 more rows</code></pre>
<p><em>A distribution and a sample of draws from that distribution are different things.</em> But, if you squint, they are sort of the same thing, at least for our purposes. For example, if you want to know the mean of the distribution, then the mean of the draws will be a fairly good estimate, especially if the number of draws is large enough.</p>
<!-- DK: Need more here. Connect to the discussion in Section 2.9 -->
<p>Recall from Chapter <a href="wrangling.html#wrangling">2</a> how we can draw randomly from specified probability distributions:</p>
<div class="sourceCode" id="cb585"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></code></pre></div>
<pre><code>##  [1]  2.234  2.232 -0.624 -0.014  2.370  0.428 -0.556  0.688 -0.632  0.556</code></pre>
<div class="sourceCode" id="cb587"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/Uniform.html">runif</a></span><span class="op">(</span><span class="fl">10</span><span class="op">)</span></code></pre></div>
<pre><code>##  [1] 0.86 0.94 0.41 0.67 0.29 0.21 0.54 0.37 0.48 0.80</code></pre>
<p>The elements of these vectors are all “draws” from the specified probability distributions. In most applied situations, our tools will produce draws rather than summary objects. Fortunately, a vector of draws is very easy to work with. Start with summary statistics:</p>
<div class="sourceCode" id="cb589"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="co"># recall mean, media, standard deviation and mad functions.</span>

<span class="va">key_stats</span> <span class="op">&lt;-</span> <span class="va">draws</span> |&gt; 
  <span class="fu"><a href="https://dplyr.tidyverse.org/reference/summarise.html">summarize</a></span><span class="op">(</span>mn <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="va">electoral_votes</span><span class="op">)</span>,
            md <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/median.html">median</a></span><span class="op">(</span><span class="va">electoral_votes</span><span class="op">)</span>,
            sd <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/sd.html">sd</a></span><span class="op">(</span><span class="va">electoral_votes</span><span class="op">)</span>,
            mad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/stats/mad.html">mad</a></span><span class="op">(</span><span class="va">electoral_votes</span><span class="op">)</span><span class="op">)</span>

<span class="va">key_stats</span></code></pre></div>
<pre><code>## # A tibble: 1 × 4
##      mn    md    sd   mad
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1  325.   326  86.9  101.</code></pre>
<p>Calculate a 95% interval directly:</p>
<div class="sourceCode" id="cb591"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/stats/quantile.html">quantile</a></span><span class="op">(</span><span class="va">draws</span><span class="op">$</span><span class="va">electoral_votes</span>, probs <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0.025</span>, <span class="fl">0.975</span><span class="op">)</span><span class="op">)</span></code></pre></div>
<pre><code>##  2.5% 97.5% 
##   172   483</code></pre>
<p>Approximate the 95% interval in two ways:</p>
<div class="sourceCode" id="cb593"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">key_stats</span><span class="op">$</span><span class="va">mn</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">key_stats</span><span class="op">$</span><span class="va">sd</span>, 
  <span class="va">key_stats</span><span class="op">$</span><span class="va">mn</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">key_stats</span><span class="op">$</span><span class="va">sd</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 152 499</code></pre>
<div class="sourceCode" id="cb595"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="va">key_stats</span><span class="op">$</span><span class="va">md</span> <span class="op">-</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">key_stats</span><span class="op">$</span><span class="va">mad</span>, 
  <span class="va">key_stats</span><span class="op">$</span><span class="va">md</span> <span class="op">+</span> <span class="fl">2</span> <span class="op">*</span> <span class="va">key_stats</span><span class="op">$</span><span class="va">mad</span><span class="op">)</span></code></pre></div>
<pre><code>## [1] 124 528</code></pre>
<p>In this case, using the mean and standard deviation produces a 95% interval which is closer to the true interval. In other cases, the median and scaled median absolute deviation will do better. Either approximation is generally “good enough” for most work. But, if you need to know the exact 95% interval, you must use <code><a href="https://rdrr.io/r/stats/quantile.html">quantile()</a></code>.</p>
</div>
<div id="cardinal-virtues" class="section level2" number="5.8">
<h2>
<span class="header-section-number">5.8</span> Cardinal Virtues<a class="anchor" aria-label="anchor" href="#cardinal-virtues"><i class="fas fa-link"></i></a>
</h2>
<!-- Wisdom: The ideal Preceptor table will generally not have any rows for data we actually have. We never really care about the causal effect in election X specifically. We want to make claims about elections in general. -->
<!-- With population, we make a distinction between Wisdom --- Are the rows from the same population? --- and Justice --- Are the rows we have data for *representative* of that population? That works nicely! Can we do the same thing wit columns? In our ideal Preceptor Table, we have a column called "treatment" which specifies the postcards we might send. With Wisdom, we need to decide if that treatment is drawn from the same population (?) of conceivable treatments as the "treatment" which was used in our data. Are the different things labelled "treatment" close enough that we can stack them in the same tibble? If no, then we give up. We can't go further. -->
<!-- Justice: Actual Preceptor Table, which is different from the ideal Preceptor Table in two ways. First, it includes the data we have. That is, it has more rows. Second, it has a bunch of missing values. (We could make an artificial distinction and say that the ideal Preceptor table never includes rows for data we have, but that is probably a bidge too far. Then again, with a time column, it is almost always true.) Then, representativeness (rows), validity (columns). In the ideal case, the data we have is perfectly representative of the population we want to estimate. That is, it is a random sample. In the ideal case, the columns mean the same thing in all rows. They are perfectly valid, but that is often not true. -->
<!-- If we lack perfect representativeness and/or perfect validity, then we can try to fix our mathematical structure. Or, we can just keep those failures in the back of our mind and then approach the posteriors we create -->
<!-- Assignment mechanism? Sampling mechanism? Missing data mechanisms in general? -->
<!-- Only the main functional form, with no variable names. Discussion of the error term. -->
<!-- Courage: For each model, write down the math, estimate the model, say something sensible about the regression table. Testing is stupid. -->
<!-- Temperance. Answer the question. Create a newobs, plug it into the model, calculate the outcome. Don't forget to add the error term if you are predicting. Then plot it. Be aware of the limits to the accuracy of your answer. Preceptor's Posterior.  All the cool themes. Bring it all together. Make the students say "Ahhh!" -->
<p>The four <a href="https://en.wikipedia.org/wiki/Cardinal_virtues">Cardinal Virtues</a> are Wisdom, Justice, Courage, and Temperance. Because data science is, ultimately, a moral act, we use these virtues to guide our work. Every data science project begins with a question.</p>
<ul>
<li><p><em>Wisdom</em> starts by creating the Preceptor Table. What data, if we had it, would allow us to answer our question easily? If the Preceptor Table has one outcome, then the model is <em>predictive</em>. If it has more than one (potential) outcome, then the model is <em>causal</em>. We then explore the data we have. You can never look too closely at your data. Key question: Are the data we have close enough to the data we want (i.e., the Preceptor Table) that we can consider both as coming from the same <em>population</em>? If not, we can’t proceed further. Key in making that decision is the assumption of <em>validity</em>. Do the columns in the Preceptor Table match the columns in the data?</p></li>
<li><p><em>Justice</em> starts with the Population Table – the data we want to have, the data which we actually have and all the other data from that same <em>population</em>. Each row of the Population Table is defined by a unique Unit/Time combination. We explore two key issues about the Population Table. First, does the relationship among the variables demonstrate <em>stability</em>, meaning is the model stable across different time periods? Third, are the rows associated with the data <em>representative</em> of all the units which we might have had data for from that time period? Justice concludes by making an assumption about the <em>data generating mechanism</em>. What general mathematical formula connects the outcome variable we are interested in with the other data that we have?</p></li>
<li><p><em>Courage</em> allows us to explore different models. Even though Justice has provided the basic mathematical structure of the model, we still need to decide which variables to include and to estimate the values of unknown parameters. We avoid hypothesis tests. We check our models for consistency with the data we have. We select one model.</p></li>
<li><p><em>Temperance</em> guides us in the use of the model we have created to answer the questions we began with. We create posteriors of <em>quantities of interest</em>. We should be modest in the claims we make. The posteriors we create are never the “truth.” The assumptions we made to create the model are never perfect. Yet decisions made with flawed posteriors are almost always better than decisions made without them.</p></li>
</ul>
<div id="wisdom" class="section level3" number="5.8.1">
<h3>
<span class="header-section-number">5.8.1</span> Wisdom<a class="anchor" aria-label="anchor" href="#wisdom"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-436"></span>
<img src="other/images/Wisdom.jpg" alt="Wisdom." width="100%"><p class="caption">
FIGURE 5.3: Wisdom.
</p>
</div>
<p>Wisdom helps us decide if we can even hope to answer our question with the data we have.</p>
<p>First, start with the Preceptor Table. What rows and columns of data do you need such that, if you had them all, the calculation of the quantity of interest would be trivial? If you want to know the average height of an adult in India, then the Preceptor Table would include a row for each adult and a column for their height. With no missing data, the average is easy to determine, as are a wide variety of other <em>estimands</em>, other unknown values.</p>
<p>One key aspect of this Preceptor Table is whether or not we need more than one potential outcome in order to calculate our estimand. For example, if we want to know the causal effect of exposure to Spanish-speakers on attitude toward immigration then we need a causal model, one which estimates that attitude for each person under both treatment and control. The Preceptor Table would require two columns for the outcome. If, on the other hand, we only want to predict someone’s attitude, or compare one person’s attitude to another’s, then we would only need a Preceptor Table with one column for the outcome.</p>
<p>Are we are modeling (just) for prediction or are we (also) modeling for causation? Predictive models care nothing about causation. Causal models are often also concerned with prediction, if only as a means of measuring the quality of the model.</p>
<p>Every model is predictive, in the sense that, if we give you new data — and it is drawn from the same population — then you can create a predictive forecast. But only a subset of those models are causal, meaning that, <em>for a given individual</em>, you can change the value of one input and figure out what the new output would be and then, from that, calculate the causal effect by looking at the difference between two potential outcomes.</p>
<p>With prediction, all we care about is forecasting Y given X on some as-yet-unseen data. But there is no notion of “manipulation” in such models. We don’t pretend that, for Joe, we could turn variable X from a value of 5 to a value of 6 by just turning some knob and, by doing so, cause Joe’s value of Y to change from 17 to 23. We can compare two people (or two groups of people), one with X equal to 5 and one with X equal to 6, and see how they differ in Y. The basic assumption of predictive models is that there is only one possible Y for Joe. There are not, by assumption, two possible values for Y, one if X equal 5 and another if X equals 6. The Preceptor Table has a single column under Y.</p>
<p>With causal inference, however, we can consider the case of Joe with <span class="math inline">\(X = 5\)</span> and Joe with <span class="math inline">\(X = 6\)</span>. The same mathematical model can be used. And both models can be used for prediction, for estimating what the value of Y will be for a yet-unseen observation with a specified value for X. But, in this case, instead of only a single column in the Preceptor Table for Y, we have at least two (and possibly many) such columns, one for each of the potential outcomes under consideration.</p>
<p><em>The difference between prediction models and causal models is that the former have one column for the outcome variable and the latter have more than one.</em></p>
<p>Second, we look at the data we have and perform an exploratory data analysis, an EDA. You can never look at your data too much. The most important variable is the one we most want to understand/explain/predict. In the models we create in later chapters, this variable will go on the left-hand side of our mathematical equations. Some academic fields refer to this as the “dependent variable.” Others use terms like “regressor” or “outcome.” Whatever the terminology, we need to explore the distribution of this variable, its min/max/range, its mean and median, its standard deviation, and so on.</p>
<p><span class="citation">Gelman, Hill, and Vehtari (<a href="references.html#ref-roas" role="doc-biblioref">2020</a>)</span> write:</p>
<blockquote>
<p>Most important is that the data you are analyzing should map to the research question you are trying to answer. This sounds obvious but is often overlooked or ignored because it can be inconvenient. Optimally, this means that the outcome measure should accurately reflect the phenomenon of interest, the model should include all relevant predictors, and the model should generalize to the cases to which it will be applied.</p>
</blockquote>
<blockquote>
<p>For example, with regard to the outcome variable, a model of incomes will not necessarily tell you about patterns of total assets. A model of test scores will not necessarily tell you about child intelligence or cognitive development. …</p>
</blockquote>
<p>We care about other variables as well, especially those that are most correlated/connected with the outcome variable. The more time that we spend looking at these variables, the more likely we are to create a useful model.</p>
<p>Third, a key concept is the <em>population</em>. We need the data we want — the Preceptor Table — and the data we have to be similar enough that we can consider them as all having come from the same statistical population. From <a href="https://en.wikipedia.org/wiki/Statistical_population">Wikipedia</a>:</p>
<blockquote>
<p>In statistics, a population is a set of similar items or events which is of interest for some question or experiment. A statistical population can be a group of existing objects (e.g. the set of all stars within the Milky Way galaxy) or a hypothetical and potentially infinite group of objects conceived as a generalization from experience (e.g. the set of all opening hands in all the poker games in Las Vegas tomorrow).</p>
</blockquote>
<p>Mechanically, assuming that the Precetor Table and the data are drawn from the same population is the same thing as “stacking” the two on top of each other. For that to make sense, the variables must mean the same thing — at least mostly — in both sources. This is the assumption of <em>validity</em>. For example, if the Preceptor Table concerns who people will vote for in the election next week and the data is from a survey taken last week, it is not obvious that we can consider the data as coming from the same population. After all, voting and survey responses are not exactly the same thing. We can only assume that they are — which is precisely what everyone who forecasts elections does — if we assume that both are “valid” measures of the same underlying construct.</p>
<p>If we assume that the data we have is drawn from the same population as the data in the Preceptor Table, then we can use information about the former to make inferences about the latter. We can combine the Preceptor Table and the data into a single <em>Population Table</em>. If we can’t do that, if we can’t assume that the two sources come from the same population, then we can’t use our data to answer our questions. We have no choice but to walk away. The heart of Wisdom is knowing when to walk away. As John Tukey noted:</p>
<blockquote>
<p>The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.</p>
</blockquote>
</div>
<div id="justice" class="section level3" number="5.8.2">
<h3>
<span class="header-section-number">5.8.2</span> Justice<a class="anchor" aria-label="anchor" href="#justice"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-437"></span>
<img src="other/images/Justice.jpg" alt="Justice." width="100%"><p class="caption">
FIGURE 5.4: Justice.
</p>
</div>
<p>After Wisdom, we have an <em>Population Table.</em> It includes rows for the data we have and the data we want to have. It has missing values, most importantly for potential outcomes which were not observed. The central problem in inference is to fill in the question marks in the Population Table.</p>
<p>There are two key issues to explore in any Population Table: stability and representativeness.</p>
<ul>
<li><p><em>Stability</em> assumes that the relationship between the outcome variable and the covariates is consistent over time. Never forget that <em>temporal</em> nature of almost all real data science problems. Our Preceptor Table will focus on rows for today or for the near future. The data we have will always be from before today. We must almost always assume that the future will be like the past in order to use data from the past to make predictions about the future.</p></li>
<li><p><em>Representativeness</em> is a two-sided concern. We want the data we have to be representative of the population for which we need to calculate parameters. Ideally, we would love for our data to be randomly sampled from the population, but this is almost never the case. But this is concern, not just with our data, but also for our Preceptor Table. If the data we want is not representative of the entire population then we will need to be careful in the inferences which we draw.</p></li>
</ul>
<p><em>Validity is about the columns in our Population Table. Stability and representativeness are about the rows.</em></p>
<p>The last step of Justice is to make an assumption about the structure of the data generating mechanism (DGM): the mathematical formula, and associated error term, which relates our outcome variable to our covariates.</p>
<p><em>Justice requires math.</em> Consider a model of coin-tossing:</p>
<p><span class="math display">\[ H_i  \sim B(\rho_H, n = 20) \]</span></p>
<p>The total number <span class="math inline">\(H\)</span> of Heads in experiment <span class="math inline">\(i\)</span> with 20 flips of a single coin, <span class="math inline">\(H_i\)</span>, is distributed as a binomial with <span class="math inline">\(n = 20\)</span> and an unknown probability <span class="math inline">\(\rho_h\)</span> of the coin coming up Heads.</p>
<p>Note:</p>
<ul>
<li><p>This is a cheat and a simplification! We are Bayesians but we have not specified the full Bayesian machinery. We really need priors on the unknown parameter <span class="math inline">\(\rho_h\)</span> as well. But that is too complex for an introductory textbook, so we wave our hands, accept the default sensible parameters built into the R packages we use, and point readers to more advanced books, like <span class="citation">Gelman, Hill, and Vehtari (<a href="references.html#ref-roas" role="doc-biblioref">2020</a>)</span>.</p></li>
<li><p>Defining <span class="math inline">\(\rho_h\)</span> as the “the probability that the coin comes up Heads” is a bit of a fudge. If you calculate that by hand and then compare it to what our tools produce, they won’t be the same. Instead, the calculated value will be closer to zero. Why? <span class="math inline">\(\rho_h\)</span> is really the “long-run percentage of the time the coin comes up Heads.” It is not just the percentage from this experiment.</p></li>
</ul>
<!-- DK: Unclear --><ul>
<li>In this simple case, we are fortunate that the parameter <span class="math inline">\(\rho_h\)</span> has such a (mostly!) simple analog to a real world quantity. Most of the time, parameters are not so easy to interpret. In a more complex model, especially with one with interaction terms, we focus less on parameters and more on actual predictions.</li>
</ul>
</div>
<div id="courage" class="section level3" number="5.8.3">
<h3>
<span class="header-section-number">5.8.3</span> Courage<a class="anchor" aria-label="anchor" href="#courage"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-438"></span>
<img src="other/images/Courage.jpg" alt="Courage." width="100%"><p class="caption">
FIGURE 5.5: Courage.
</p>
</div>
<p>The three languages of data science are words, math and code, and the most important of these is code. We need to explain the structure of our model using all three languages, but we need <em>Courage</em> to implement the model in code.</p>
<p>Courage requires us to take the general mathematical formula provide by Justice and then make it specific. Which variables should we include in the model and which do we exclude? Every data science project involves the creation of several models. For each, we specify the precise data generating mechanism. Using that formula, and some R code, we create a fitted model. All models have parameters. We can never know the true values of the parameters, but we can create, and explore, posterior distributions for those unknown true values.</p>
<p>Code allows us to “fit” a model by estimating the values of the unknown parameters, like <span class="math inline">\(\rho_h\)</span>. Sadly, we can never know the true values of these parameters. But, like all good data scientists, we can express our uncertain knowledge in the form of posterior probability distributions. With those distributions, we can compare the actual values of the outcome variable with the “fitted” or “predicted” results of the model. We can examine the “residuals,” the difference between the fitted and actual values.</p>
<p>Every outcome is the sum of two parts: the model and what is not in the model:</p>
<p><span class="math display">\[outcome = model + what\ is\ not\ in\ the\ model\]</span></p>
<p>It doesn’t matter what the outcome is. It could be the result of a coin flip, the weight of a person, the GDP of a country. Whatever <em>outcome</em> we are considering is always made up of two parts. The first is the model we have created. The second is all the stuff — all the blooming and buzzing complexity of the real world — which is not a part of the model.</p>
<p>Some of our uncertainty is driven by our ignorance about <span class="math inline">\(\rho_h\)</span>.</p>
<p>A parameter is something which does not exist in the real world. (If it did, or could, then it would be data.) Instead, a parameter is a mental abstraction, a building block which we will use to to help us accomplish our true goal: To replace at least some of the questions marks in the actual Preceptor Table. Since parameters are mental abstractions, we will always be uncertain as to their value, however much data we might collect.</p>
<p>But some, often most, of the uncertainty comes from forces that are, by assumption, not in the model. For example, if the coin is fair, we expect <span class="math inline">\(T_i\)</span> to equal 10. But, often, it will be different, even if we are correct and <span class="math inline">\(\rho_h\)</span> equals exactly 0.5.</p>
<p><em>Some randomness is intrinsic in this fallen world.</em></p>
</div>
<div id="temperance" class="section level3" number="5.8.4">
<h3>
<span class="header-section-number">5.8.4</span> Temperance<a class="anchor" aria-label="anchor" href="#temperance"><i class="fas fa-link"></i></a>
</h3>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-439"></span>
<img src="other/images/Temperance.jpg" alt="Temperance." width="100%"><p class="caption">
FIGURE 5.6: Temperance.
</p>
</div>
<p>There are few more important concepts in statistics and data science than the “Data Generating Mechanism.” Our <em>data</em> — the data that we collect and see — has been <em>generated</em> by the complexity and confusion of the world. God’s own <em>mechanism</em> has brought His data to us. Our job is to build a model of that process, to create, on the computer, a mechanism which generates fake data consistent with the data which we see. With that DGM, we can answer any question which we might have. In particular, with the DGM, we provide predictions of data we have not seen and estimates of the uncertainty associated with those predictions. <em>Justice</em> gave us the structure of the DGM. <em>Courage</em> created the DGM, the fitted model. <em>Temperance</em> will guide us in its use.</p>
<p>Having created (and checked) a model, we now use the model to answer questions. Models are made for use, not for beauty. The world confronts us. Make decisions we must. Our decisions will be better ones if we use high quality models to help make them.</p>
<p>Sadly, our models are never as good as we would like them to be. First, the world is intrinsically uncertain.</p>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-440"></span>
<img src="05-probability/images/donald_rumsfeld.jpg" alt="Donald Rumsfeld." width="100%"><p class="caption">
FIGURE 5.7: Donald Rumsfeld.
</p>
</div>
<blockquote>
<p>There are known knowns. There are things we know we know. We also know there are known unknowns. That is to say, we know there are some things we do not know. But there are also unknown unknowns, the ones we do not know we do not know. – Donald Rumsfeld</p>
</blockquote>
<p>What we really care about is data we haven’t seen yet, mostly data from tomorrow. But what if the world changes, as it always does? If it doesn’t change much, maybe we are OK. If it changes a lot, then what good will our model be? In general, the world changes some. That means that are forecasts are more uncertain that a naive use of our model might suggest.</p>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-441"></span>
<img src="05-probability/images/Three_Card_Monte.jpg" alt="Three Card Monte." width="100%"><p class="caption">
FIGURE 5.8: Three Card Monte.
</p>
</div>
<p>What does this mean? Well imagine a crowd playing Three Card Monte in the streets of New York. The guy running the game runs a demo and shows you all the cards to make you confident. They earn money by making you overconfident and persuading you to bet. Your odds may seem good during the demo round, but that doesn’t actually say anything about what will likely happen when the real, high stakes game begins. The person running the game does many simulations, making the “victim” forget that they cannot actually make any conclusions about the odds of winning. There are some variables that we simply do not know even if we put a lot of effort into making posterior probability distributions. People can be using slight of hand, for instance.</p>
<p>We need patience in order to study and understand the unknown unknowns in our data. Patience is also important when we analyze the “realism” of our models. When we created the mathematical probability distribution for presidential elections, for instance, we assumed that the Democratic candidate would have a 50% chance of winning each vote in the electoral college. By comparing the mathematical model to our empirical cases, however, we recognize that the mathematical model is unlikely to be true. The mathematical model suggested that getting fewer than 100 votes is next to impossible, but many past Democratic candidates in the empirical distribution received less than 100 electoral votes.</p>
<p>In Temperance, the key distinction is between the <em>true</em> posterior distribution — what we will call “Preceptor’s Posterior” — and the estimated posterior distribution. Recall our discussion from Section <a href="probability.html#distributions">5.1</a>. Imagine that every assumption we made in Wisdom and Justice were correct, that we correctly understand every aspect of how the world works. We still would not know the unknown value we are trying to estimate — recall the Fundamental Problem of Causal Inference — but the posterior we created would be perfect. That is Preceptor’s Posterior. Sadly, even if our estimated posterior is, very close to Preceptor’s Posterior, we can never be sure of that fact, because we can never know the truth, never be certain that all the assumptions we made are correct.</p>
<p>Even worse, we must always worry that our estimated posterior, despite all the work we put into creating it, is far from the truth. We, therefore, must be cautious in our use of that posterior, humble in our claims about its accuracy. Using our posterior, despite its fails, is better than not using it. Yet it is, as best, a distorted map of reality, a glass through which we must look darkly. Use your posterior with humility.</p>
<!-- DK: Could do more here. Show the iterative process of model building, including posterior predictive checks. -->
<!-- Null hypothesis testing is a mistake. There is only the data, the models and the summaries therefrom. Describe an hypothesis test each chapter, and then dismiss it. Play the prediction game. That, perhaps, provides a useful framework for why NHST is stupid. Or, rather, you play the prediction game to figure out which statistical procedures are best --- and or, how well procedure X works --- and then use that information to make a decision. Explain what a test is, and why we think it is a waste of time to do them, and why people do them anyway. Key issue: If p = 0.04 really makes you do something totally different than p = 0.06, then either you (or the system within which you are operating) is stupid. -->
</div>
</div>
<div id="summary-6" class="section level2" number="5.9">
<h2>
<span class="header-section-number">5.9</span> Summary<a class="anchor" aria-label="anchor" href="#summary-6"><i class="fas fa-link"></i></a>
</h2>
<!-- DK: Not a bad summary, but should hit the key points more clearly.  -->
<p>Throughout this Chapter, we spent time going through examples of conditional distributions. However, it’s worth noting that all probability distributions are conditional on something. Even in the most simple examples, when we were flipping a coin multiple times, we were assuming that the probability of getting heads versus tails did not change between tosses.</p>
<p>We also discussed the difference between empirical, mathematical, and posterior probability distributions. Even though we developed these heuristics to better understand distributions, every time we make a claim about the world, it is based on our beliefs - what we think about the world. We could be wrong. Our beliefs can differ. Two reasonable people can have conflicting beliefs about the fairness of a die.</p>
<p>At the start of this chapter we briefly discuss the definition of an random variable, yet we sort of let it go for the rest of the chapter, but it’s hiding almost everywhere whenever we create an distribution.
For example, in two models we have two random variables, the have disease and the don’t have disease, in three models we have three random variables, either to have 0 or 1 or 2 white marbles in bad. Essentially is just like the missing values in the Preceptor table <em>what random variables do you need to know the values of to answer the question? </em></p>
<p>It is useful to understand the three types of distributions and the concept of conditional distributions, but almost every probability distribution is conditional and posterior. We can leave out both words in future discussions, as we generally will in this book. They are implicit.</p>
<p>If you are keen to learn more about probability, here is a video featuring Professor Gary King. This is a great way to review some of the concepts we covered in this chapter, albeit at a higher level of mathematics.</p>
<iframe src="https://www.youtube.com/embed/6C7yRBfh2ok?showcase=0" width="100%" height="400px" data-external="1">
</iframe>
<!-- ```{r, echo = FALSE, fig.cap = "The truth is out there"} -->
<!-- knitr::include_graphics("05-probability/images/truth_out_there.jpg") -->
<!-- ``` -->
<!-- * *The truth is out there.* The next adult American male we meet will have a height. Right now, we don't know what it is.  -->
<!-- Notes from DeGroot Probability and Statistics and from Freund Mathemathical Statistics.  -->
<!-- Not sure how useful these are or how to incorporate them, but wanted to keep them around. -->
<!-- A random variable is a function which generates the value of an unknown variable. -->
<!-- A probability function is a set function which maps outcomes to probabilities. -->
<!-- The value of a random variable is a function of a chance experiment. -->
<!-- Probabilities are values of a set function. -->
<!-- Random variables are capital letters, like X, while real values are small letters, like x. -->
<!-- X = x is the set of elements in the sample space for which the random variable X takes on the vaklue x. -->
<!-- Freund (p. 86): Give a table and then give a formula which creates the table. That formula is the probability distribution of X. Example: -->
<!-- x     P(X = x) -->
<!-- 2       1/36 -->
<!-- 3       2/36 -->
<!-- ...     ... -->
<!-- 7       6/36 -->
<!-- ...     ... -->
<!-- 12      1/36 -->
<!-- An event or experiment os any process wh0se outcome is not known with certainty. -->
<!-- The sample space is all possible outcomes of the event. -->
<!-- DeGroot (p. 97): "Consider an experiment for which the sample space us denoted by S. A real-valued function that is defined on the space S is called a random variable. In other words, in a particular experiment a random variable X would be some function that assigns a real number X(s) to each possible outcome s \subset S. -->

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="rubin-causal-model.html"><span class="header-section-number">4</span> Rubin Causal Model</a></div>
<div class="next"><a href="one-parameter.html"><span class="header-section-number">6</span> One Parameter</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#probability"><span class="header-section-number">5</span> Probability</a></li>
<li>
<a class="nav-link" href="#distributions"><span class="header-section-number">5.1</span> Distributions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#scaling-distributions"><span class="header-section-number">5.1.1</span> Scaling distributions</a></li>
<li><a class="nav-link" href="#normalizing-distributions"><span class="header-section-number">5.1.2</span> Normalizing distributions</a></li>
<li><a class="nav-link" href="#simulating-distributions"><span class="header-section-number">5.1.3</span> Simulating distributions</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#probability-distributions"><span class="header-section-number">5.2</span> Probability distributions</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#flipping-a-coin"><span class="header-section-number">5.2.1</span> Flipping a coin</a></li>
<li><a class="nav-link" href="#rolling-two-dice"><span class="header-section-number">5.2.2</span> Rolling two dice</a></li>
<li><a class="nav-link" href="#presidential-elections"><span class="header-section-number">5.2.3</span> Presidential elections</a></li>
<li><a class="nav-link" href="#height"><span class="header-section-number">5.2.4</span> Height</a></li>
<li><a class="nav-link" href="#joint-distributions"><span class="header-section-number">5.2.5</span> Joint distributions</a></li>
<li><a class="nav-link" href="#conditional-distrubutions"><span class="header-section-number">5.2.6</span> Conditional distrubutions</a></li>
</ul>
</li>
<li><a class="nav-link" href="#list-columns-and-map-functions"><span class="header-section-number">5.3</span> List-columns and map functions</a></li>
<li><a class="nav-link" href="#two-models"><span class="header-section-number">5.4</span> Two models</a></li>
<li><a class="nav-link" href="#three-models"><span class="header-section-number">5.5</span> Three models</a></li>
<li><a class="nav-link" href="#n-models"><span class="header-section-number">5.6</span> N models</a></li>
<li><a class="nav-link" href="#working-with-probability-distributions"><span class="header-section-number">5.7</span> Working with probability distributions</a></li>
<li>
<a class="nav-link" href="#cardinal-virtues"><span class="header-section-number">5.8</span> Cardinal Virtues</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#wisdom"><span class="header-section-number">5.8.1</span> Wisdom</a></li>
<li><a class="nav-link" href="#justice"><span class="header-section-number">5.8.2</span> Justice</a></li>
<li><a class="nav-link" href="#courage"><span class="header-section-number">5.8.3</span> Courage</a></li>
<li><a class="nav-link" href="#temperance"><span class="header-section-number">5.8.4</span> Temperance</a></li>
</ul>
</li>
<li><a class="nav-link" href="#summary-6"><span class="header-section-number">5.9</span> Summary</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/PPBDS/primer/blob/master/05-probability.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/PPBDS/primer/edit/master/05-probability.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Preceptor’s Primer for Bayesian Data Science</strong>" was written by David Kane. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
